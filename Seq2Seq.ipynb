{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandhc6/Assignment-3/blob/main/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhDxe46ViCCn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "from random import randrange \n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zRhhFwXid4u",
        "outputId": "b5fb6f04-ace1-4bc0-d4bc-ec55493cbf23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-06 19:25:48--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.97.128, 142.251.107.128, 173.194.210.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.97.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   225MB/s    in 9.1s    \n",
            "\n",
            "2022-05-06 19:25:57 (212 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf 'dakshina_dataset_v1.0.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQdGUuUTDj1m",
        "outputId": "64ad0414-12f5-403b-faac-ce6370fc8198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['பரிந்துரை\\tparinthurai\\t2', 'எடுப்பதில்லை\\tyeduppathillai\\t1']\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "# epochs = 10  # Number of epochs to train for.\n",
        "# latent_dim = 256  # Latent dimensionality of the encoding space. #hidden states hyperparameter\n",
        "# Path to the data txt file on disk.\n",
        "train_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
        "val_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
        "# open and save the files to lists\n",
        "with open(train_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_lines = f.read().split(\"\\n\")\n",
        "with open(val_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    val_lines = f.read().split(\"\\n\")\n",
        "# popping the last element of all the lists since it is empty character\n",
        "train_lines.pop()\n",
        "val_lines.pop()\n",
        "random.shuffle(train_lines)\n",
        "print(train_lines[0:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6wy9xCNDc0u"
      },
      "outputs": [],
      "source": [
        "# embedding train model\n",
        "def embedding_train(train_lines):\n",
        "\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "    # go through the train lines and split them into 3 and save input and target\n",
        "    for line in train_lines[: (len(train_lines) - 1)]:\n",
        "        # because we want english to devanagiri conversion\n",
        "        target_text, input_text, _ = line.split(\"\\t\")\n",
        "        # We use \"tab\" as the \"start sequence\" character\n",
        "        # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "        target_text = \"\\t\" + target_text + \"\\n\"\n",
        "        # append it to the main input texts list\n",
        "        input_texts.append(input_text)\n",
        "        # append it to the main target texts list\n",
        "        target_texts.append(target_text)\n",
        "        # to find the number of unique characters in both\n",
        "        for char in input_text:\n",
        "            if char not in input_characters:\n",
        "                input_characters.add(char)\n",
        "        for char in target_text:\n",
        "            if char not in target_characters:\n",
        "                target_characters.add(char)\n",
        "    # add the space character to both\n",
        "    input_characters.add(\" \")\n",
        "    target_characters.add(\" \")\n",
        "    # sort it\n",
        "    input_characters = sorted(list(input_characters))\n",
        "    target_characters = sorted(list(target_characters))\n",
        "    # find the number\n",
        "    num_encoder_tokens = len(input_characters)\n",
        "    num_decoder_tokens = len(target_characters)\n",
        "    # find the maximum length of input word and target word\n",
        "    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "    \n",
        "    print(\"Number of samples:\", len(input_texts))\n",
        "    print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "    print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "    # create an index\n",
        "    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "   \n",
        "    # create an 0 array for encoder input size of (input_texts,max_seqlen,tokens)\n",
        "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length), dtype=\"float32\")\n",
        "    # create decoder input\n",
        "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length), dtype=\"float32\")\n",
        "    # create decoder target\n",
        "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "    # for each sample convert it into character encoding i.e. if\n",
        "    # at that position a character is present then encode the index of that character there\n",
        "    # this is done for both encoder and decoder input data for further word embedding\n",
        "    # but target data is one hot encoded.\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t] = input_token_index[char]\n",
        "        # remaining positions set as empty space\n",
        "        encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "        # similarly do for decoder data\n",
        "        for t, char in enumerate(target_text):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            decoder_input_data[i, t] = target_token_index[char]\n",
        "            # check if t >0 since decoder targer data is ahead\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "        # append both the remaining positions of both the datas with empty space\n",
        "        decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "        decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "    return encoder_input_data,decoder_input_data,decoder_target_data,num_encoder_tokens,num_decoder_tokens,input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N80Xht1DZvW"
      },
      "outputs": [],
      "source": [
        "# embedding validation data\n",
        "# for validation data, almost same\n",
        "def embedding_val(val_lines,num_decoder_tokens,input_token_index,target_token_index):\n",
        "    val_input_texts = []\n",
        "    val_target_texts = []\n",
        "    \n",
        "    for line in val_lines[: (len(val_lines) - 1)]:\n",
        "        target_text, input_text, _ = line.split(\"\\t\")\n",
        "        # We use \"tab\" as the \"start sequence\" character\n",
        "        # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "        target_text = \"\\t\" + target_text + \"\\n\"\n",
        "        val_input_texts.append(input_text)\n",
        "        val_target_texts.append(target_text)\n",
        "    val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
        "    val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
        "    val_encoder_input_data = np.zeros(\n",
        "        (len(val_input_texts), val_max_encoder_seq_length), dtype=\"float32\")\n",
        "    val_decoder_input_data = np.zeros(\n",
        "        (len(val_input_texts), val_max_decoder_seq_length), dtype=\"float32\")\n",
        "    val_decoder_target_data = np.zeros(\n",
        "        (len(val_input_texts), val_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "    for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            val_encoder_input_data[i, t] = input_token_index[char]\n",
        "        val_encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "        for t, char in enumerate(target_text):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            val_decoder_input_data[i, t] = target_token_index[char]\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "        val_decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "        val_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "    return val_encoder_input_data,val_decoder_input_data,val_decoder_target_data,target_token_index,val_target_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SphcvHgrD6D2",
        "outputId": "36807960-98ee-4ff7-b7c6-be67af522217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 68217\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n"
          ]
        }
      ],
      "source": [
        "#Embedding data\n",
        "encoder_input_data,decoder_input_data,decoder_target_data,num_encoder_tokens,num_decoder_tokens,input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length = embedding_train(train_lines)\n",
        "val_encoder_input_data,val_decoder_input_data,val_decoder_target_data,target_token_index,val_target_texts = embedding_val(val_lines,num_decoder_tokens,input_token_index,target_token_index)\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUI2TAQlVWlM"
      },
      "outputs": [],
      "source": [
        "#yoursssss\n",
        "\n",
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 2  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space. #hidden states hyperparameter\n",
        "# Path to the data txt file on disk.\n",
        "train_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
        "val_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
        "# open and save the files to lists\n",
        "with open(train_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_lines = f.read().split(\"\\n\")\n",
        "with open(val_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    val_lines = f.read().split(\"\\n\")\n",
        "# popping the last element of all the lists since it is empty character\n",
        "train_lines.pop()\n",
        "val_lines.pop()\n",
        "random.shuffle(train_lines)\n",
        "print(train_lines[0:2])\n",
        "\n",
        "# embedding pre processing\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "# go through the train lines and split them into 3 and save input and target\n",
        "for line in train_lines[: (len(train_lines) - 1)]:\n",
        "    # because we want english to devanagiri conversion\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    # append it to the main input texts list\n",
        "    input_texts.append(input_text)\n",
        "    # append it to the main target texts list\n",
        "    target_texts.append(target_text)\n",
        "    # to find the number of unique characters in both\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# add the space character to both\n",
        "input_characters.add(\" \")\n",
        "target_characters.add(\" \")\n",
        "# sort it\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "# find the number\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "# find the maximum length of input word and target word\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "# create an index\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "print((input_token_index))\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "print((target_token_index))\n",
        "# create an 0 array for encoder input size of (input_texts,max_seqlen,tokens)\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "# create decoder input\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "# create decoder target\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "# for each sample convert it into character encoding i.e. if\n",
        "# at that position a character is present then encode the index of that character there\n",
        "# this is done for both encoder and decoder input data for further word embedding\n",
        "# but target data is one hot encoded.\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    # remaining positions set as empty space\n",
        "    encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "    # similarly do for decoder data\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[char]\n",
        "        # check if t >0 since decoder targer data is ahead\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    # append both the remaining positions of both the datas with empty space\n",
        "    decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n",
        "# for validation data,\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "for line in val_lines[: (len(val_lines) - 1)]:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    val_input_texts.append(input_text)\n",
        "    val_target_texts.append(target_text)\n",
        "val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
        "val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
        "val_encoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), val_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), val_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_target_data = np.zeros(\n",
        "    (len(val_input_texts), val_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_encoder_input_data[i, t] = input_token_index[char]\n",
        "    val_encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    val_decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "    val_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_awjGcVVsdm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLqfVhxah7U6"
      },
      "outputs": [],
      "source": [
        "def seq2seq(embedding_size, n_encoder_tokens, n_decoder_tokens, n_encoder_layers,\n",
        "                 n_decoder_layers, latent_dimension, cell_type,\n",
        "                 target_token_index, max_decoder_seq_length, reverse_target_char_index,\n",
        "                 dropout,encoder_input_data, decoder_input_data,\n",
        "                decoder_target_data,\n",
        "                batch_size,epochs):\n",
        "  encoder_inputs = keras.Input(shape=(None,), name='encoder_input')\n",
        "  # word embedding layer\n",
        "  encoder = None\n",
        "  encoder_outputs = None\n",
        "  state_h = None\n",
        "  state_c = None\n",
        "  e_layer=n_encoder_layers\n",
        "\n",
        "  if cell_type==\"RNN\":\n",
        "    embed = tf.keras.layers.Embedding(input_dim=n_encoder_tokens, output_dim=embedding_size,\n",
        "                                             name='encoder_embedding')(encoder_inputs)\n",
        "    encoder = keras.layers.SimpleRNN(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                             name='encoder_hidden_1', dropout=dropout)\n",
        "    print(\"Embed done\")\n",
        "    encoder_outputs, state_h = encoder(embed)\n",
        "    for i in range(2,e_layer+1):\n",
        "      layer_name = ('encoder_hidden_%d') % i\n",
        "      print(\"Starting 2nd\")\n",
        "      encoder = keras.layers.SimpleRNN(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                                 name=layer_name, dropout=dropout)\n",
        "      print(\"Ending 2nd\")\n",
        "\n",
        "      encoder_outputs, state_h = encoder(encoder_outputs, initial_state=[state_h])\n",
        "    encoder_states = None\n",
        "    encoder_states = [state_h]\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), name='decoder_input')\n",
        "    embed_dec = tf.keras.layers.Embedding(n_decoder_tokens, embedding_size, name='decoder_embedding')(\n",
        "        decoder_inputs)\n",
        "    # number of decoder layers\n",
        "    d_layer = n_decoder_layers\n",
        "    decoder = None\n",
        "    decoder = keras.layers.SimpleRNN(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                             name='decoder_hidden_1', dropout=dropout)\n",
        "    # all decoders the initial state is encoder last state of last layer\n",
        "    decoder_outputs, _ = decoder(embed_dec, initial_state=encoder_states)\n",
        "    for i in range(2,d_layer+1):\n",
        "      layer_name = 'decoder_hidden_%d' % i\n",
        "      decoder = keras.layers.SimpleRNN(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                                 name=layer_name, dropout=dropout)\n",
        "      decoder_outputs, _ = decoder(decoder_outputs, initial_state=encoder_states)\n",
        "    decoder_dense = keras.layers.Dense(n_decoder_tokens, activation=\"softmax\", name='decoder_output')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    \n",
        "    model.compile(\n",
        "          optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
        "          metrics=['accuracy'])#, metrics=[my_metric]                 \n",
        "\n",
        "    # earlystopping = EarlyStopping(\n",
        "    #     monitor=\"val_loss\", min_delta=0.01, patience=5, verbose=2, mode=\"min\")\n",
        "\n",
        "    model.fit(\n",
        "          [encoder_input_data, decoder_input_data],\n",
        "          decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          callbacks=WandbCallback()\n",
        "      )\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc = model.get_layer(\n",
        "              'encoder_hidden_' + str(n_encoder_layers)).output\n",
        "    encoder_states = [state_h_enc]\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "    decoder_states_inputs = []\n",
        "    decoder_states = []\n",
        "\n",
        "    for j in range(1, n_decoder_layers + 1):\n",
        "        decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "        current_states_inputs = [decoder_state_input_h]\n",
        "        decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "        decoder_outputs, state_h_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "        decoder_states += [state_h_dec]\n",
        "        decoder_states_inputs += current_states_inputs\n",
        "    decoder_dense = model.get_layer('decoder_output')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = keras.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    )\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "  elif cell_type==\"GRU\":\n",
        "    embed = tf.keras.layers.Embedding(input_dim=n_encoder_tokens, output_dim=embedding_size,\n",
        "                                             name='encoder_embedding')(encoder_inputs)\n",
        "    encoder = keras.layers.GRU(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                             name='encoder_hidden_1', dropout=dropout)\n",
        "    encoder_outputs, state_h = encoder(embed)\n",
        "    for i in range(2,e_layer+1):\n",
        "      layer_name = ('encoder_hidden_%d') % i\n",
        "      encoder = keras.layers.GRU(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                                 name=layer_name, dropout=dropout)\n",
        "      encoder_outputs, state_h = encoder(encoder_outputs, initial_state=[state_h])\n",
        "    encoder_states = None\n",
        "    encoder_states = [state_h]\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), name='decoder_input')\n",
        "    embed_dec = tf.keras.layers.Embedding(n_decoder_tokens, embedding_size, name='decoder_embedding')(\n",
        "        decoder_inputs)\n",
        "    # number of decoder layers\n",
        "    d_layer = n_decoder_layers\n",
        "    decoder = None\n",
        "    decoder = keras.layers.GRU(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                             name='decoder_hidden_1', dropout=dropout)\n",
        "    # all decoders the initial state is encoder last state of last layer\n",
        "    decoder_outputs, _ = decoder(embed_dec, initial_state=encoder_states)\n",
        "    for i in range(2,d_layer+1):\n",
        "      layer_name = 'decoder_hidden_%d' % i\n",
        "      decoder = keras.layers.GRU(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                                 name=layer_name, dropout=dropout)\n",
        "      decoder_outputs, _ = decoder(decoder_outputs, initial_state=encoder_states)\n",
        "    decoder_dense = keras.layers.Dense(n_decoder_tokens, activation=\"softmax\", name='decoder_output')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    model.compile(\n",
        "          optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
        "          metrics=['accuracy'])#, metrics=[my_metric]                 \n",
        "\n",
        "    # earlystopping = EarlyStopping(\n",
        "    #     monitor=\"val_loss\", min_delta=0.01, patience=5, verbose=2, mode=\"min\")\n",
        "    \n",
        "    model.fit(\n",
        "          [encoder_input_data, decoder_input_data],\n",
        "          decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          #callbacks=WandbCallback()\n",
        "      )\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc = model.get_layer(\n",
        "              'encoder_hidden_' + str(n_encoder_layers)).output\n",
        "    encoder_states = [state_h_enc]\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "    decoder_states_inputs = []\n",
        "    decoder_states = []\n",
        "\n",
        "    for j in range(1, n_decoder_layers + 1):\n",
        "        decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "        current_states_inputs = [decoder_state_input_h]\n",
        "        decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "        decoder_outputs, state_h_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "        decoder_states += [state_h_dec]\n",
        "        decoder_states_inputs += current_states_inputs\n",
        "    decoder_dense = model.get_layer('decoder_output')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = keras.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    )\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "\n",
        "  elif cell_type==\"LSTM\":\n",
        "    embed = tf.keras.layers.Embedding(input_dim=n_encoder_tokens, output_dim=embedding_size,\n",
        "                                             name='encoder_embedding')(encoder_inputs)\n",
        "    encoder = keras.layers.LSTM(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                             name='encoder_hidden_1', dropout=dropout)\n",
        "    encoder_outputs, state_h, state_c = encoder(embed)\n",
        "    for i in range(2,e_layer+1):\n",
        "      layer_name = ('encoder_hidden_%d') % i\n",
        "      encoder = keras.layers.LSTM(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                                 name=layer_name, dropout=dropout)\n",
        "      encoder_outputs, state_h, state_c = encoder(encoder_outputs, initial_state=[state_h,state_c])\n",
        "    encoder_states = None\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), name='decoder_input')\n",
        "    embed_dec = tf.keras.layers.Embedding(n_decoder_tokens, embedding_size, name='decoder_embedding')(\n",
        "        decoder_inputs)\n",
        "    # number of decoder layers\n",
        "    d_layer = n_decoder_layers\n",
        "    decoder = None\n",
        "    decoder = keras.layers.LSTM(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                             name='decoder_hidden_1', dropout=dropout)\n",
        "    # all decoders the initial state is encoder last state of last layer\n",
        "    decoder_outputs, _,_ = decoder(embed_dec, initial_state=encoder_states)\n",
        "    for i in range(2,d_layer+1):\n",
        "      layer_name = 'decoder_hidden_%d' % i\n",
        "      decoder = keras.layers.LSTM(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                                 name=layer_name, dropout=dropout)\n",
        "      decoder_outputs, _,_ = decoder(decoder_outputs, initial_state=encoder_states)\n",
        "    decoder_dense = keras.layers.Dense(n_decoder_tokens, activation=\"softmax\", name='decoder_output')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    model.compile(\n",
        "          optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
        "          metrics=['accuracy'])#, metrics=[my_metric]                 \n",
        "    \n",
        "    # earlystopping = EarlyStopping(\n",
        "    #     monitor=\"val_loss\", min_delta=0.01, patience=5, verbose=2, mode=\"min\")\n",
        "    \n",
        "    model.fit(\n",
        "          [encoder_input_data, decoder_input_data],\n",
        "          decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          #callbacks=WandbCallback()\n",
        "      )\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\n",
        "              'encoder_hidden_' + str(n_encoder_layers)).output\n",
        "    encoder_states = [state_h_enc, state_c_enc]\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "    decoder_states_inputs = []\n",
        "    decoder_states = []\n",
        "\n",
        "    for j in range(1,n_decoder_layers + 1):\n",
        "        decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "        decoder_state_input_c = keras.Input(shape=(latent_dimension,))\n",
        "        current_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "        decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "        decoder_outputs, state_h_dec, state_c_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "        decoder_states += [state_h_dec, state_c_dec]\n",
        "        decoder_states_inputs += current_states_inputs\n",
        "    decoder_dense = model.get_layer('decoder_output')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = keras.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    )\n",
        "    return encoder_model, decoder_model\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEpesYgCnX4f"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq,n_decoder_layers,cell_type,encoder_model,decoder_model):\n",
        "        # Encode the input as state vectors.\n",
        "        states_value = [encoder_model.predict(input_seq)]*n_decoder_layers\n",
        "\n",
        "        # Generate empty target sequence of length 1.\n",
        "        empty_seq = np.zeros((1, 1))\n",
        "        # Populate the first character of target sequence with the start character.\n",
        "        empty_seq[0, 0] = target_token_index[\"\\t\"]\n",
        "        target_seq = empty_seq\n",
        "\n",
        "        # Sampling loop for a batch of sequences\n",
        "        # (to simplify, here we assume a batch of size 1).\n",
        "        stop_condition = False\n",
        "        decoded_sentence = \"\"\n",
        "        while not stop_condition:\n",
        "            if cell_type is not None and (cell_type.lower() == 'rnn' or cell_type.lower() == 'gru'):\n",
        "                temp = decoder_model.predict([target_seq] + [states_value])\n",
        "                output_tokens, states_value = temp[0], temp[1:]\n",
        "            else:\n",
        "                temp = decoder_model.predict([target_seq] + states_value )\n",
        "                output_tokens, states_value = temp[0], temp[1:]\n",
        "\n",
        "            # Sample a token\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "            sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "            decoded_sentence += sampled_char\n",
        "\n",
        "            # Exit condition: either hit max length\n",
        "            # or find stop character.\n",
        "            if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "                stop_condition = True\n",
        "\n",
        "            # Update the target sequence (of length 1).\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlClTo3fqaOu"
      },
      "outputs": [],
      "source": [
        "def accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model, verbose=False):\n",
        "        n_correct = 0\n",
        "        n_total = 0\n",
        "        for seq_index in range(len(val_encoder_input_data)):\n",
        "            # Take one sequence (part of the training set)\n",
        "            # for trying out decoding.\n",
        "            input_seq = val_encoder_input_data[seq_index: seq_index + 1]\n",
        "            # Generate empty target sequence of length 1.\n",
        "            # empty_seq = np.zeros((1, 1))\n",
        "            # # Populate the first character of target sequence with the start character.\n",
        "            # empty_seq[0, 0] = self.target_token_index[\"\\t\"]\n",
        "            decoded_sentence = decode_sequence(input_seq,n_decoder_layers,'LSTM',encoder_model,decoder_model)\n",
        "\n",
        "            if decoded_sentence.strip() == val_target_texts[seq_index].strip():\n",
        "                n_correct += 1\n",
        "\n",
        "            n_total += 1\n",
        "\n",
        "            if verbose:\n",
        "                print('Prediction ', decoded_sentence.strip(), ',Ground Truth ', val_target_texts[seq_index].strip())\n",
        "\n",
        "        return n_correct * 100.0 / n_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1Tv3B8JEeH-"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "embedding_size=256\n",
        "n_encoder_tokens=num_encoder_tokens\n",
        "n_decoder_tokens=num_decoder_tokens\n",
        "n_encoder_layers=3\n",
        "n_decoder_layers=3\n",
        "latent_dimension=256\n",
        "cell_type='GRU'\n",
        "target_token_index=target_token_index\n",
        "max_decoder_seq_length=max_decoder_seq_length\n",
        "reverse_target_char_index=reverse_target_char_index\n",
        "dropout=0.5\n",
        "epochs=25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAD6146NElT-"
      },
      "outputs": [],
      "source": [
        "#calling rnn\n",
        "encoder_model, decoder_model=seq2seq(embedding_size, num_encoder_tokens,num_decoder_tokens,n_encoder_layers, n_decoder_layers,latent_dimension,\n",
        "                cell_type, target_token_index, max_decoder_seq_length,reverse_target_char_index, dropout ,encoder_input_data, decoder_input_data,\n",
        "                decoder_target_data,batch_size,epochs)\n",
        "\n",
        "# val_accuracy= accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model)\n",
        "# print('Validation accuracy: ', val_accuracy)\n",
        "\n",
        "# subset = 0\n",
        "# val_accuracy = accuracy(val_encoder_input_data[0:subset], val_target_texts[0:subset],n_decoder_layers,encoder_model,decoder_model) if subset>0 \\\n",
        "#     else accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model)\n",
        "# print('Validation accuracy: ', val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSTR6NrSJ4cj"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGScPi2aJoTr"
      },
      "outputs": [],
      "source": [
        "def fit():\n",
        "  config_defaults = {\n",
        "            \"cell_type\":'LSTM',\n",
        "            \"num_encoder_layers\":2,\n",
        "            \"num_decoder_layers\":3,\n",
        "            \"embedding_size\":256,\n",
        "            \"latent_dimension\":256,\n",
        "            \"dropout\":0.2,\n",
        "            \"epochs\":25\n",
        "        }\n",
        "  wandb.init(config=config_defaults)\n",
        "\n",
        "  config = wandb.config\n",
        "  \n",
        "  cell_type=config.cell_type\n",
        "  n_encoder_layers=config.num_encoder_layers\n",
        "  n_decoder_layers=config.num_decoder_layers\n",
        "  embedding_size=config.embedding_size\n",
        "  latent_dimension=config.latent_dimension\n",
        "  dropout=config.dropout\n",
        "  epochs=config.epochs\n",
        "\n",
        "  run_name = \"cell_type_{}_nel_{}_ndl_{}_drop_{}_emd_{}_ld_{}\".format(cell_type, n_encoder_layers, n_decoder_layers, dropout, embedding_size, latent_dimension )\n",
        "  \n",
        "  encoder_model, decoder_model=seq2seq(embedding_size, num_encoder_tokens,num_decoder_tokens,n_encoder_layers, n_decoder_layers,latent_dimension,\n",
        "                cell_type, target_token_index, max_decoder_seq_length,reverse_target_char_index, dropout ,encoder_input_data, decoder_input_data,\n",
        "                decoder_target_data,batch_size,epochs)\n",
        "  \n",
        "  val_accuracy=accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model)\n",
        "  print(\"Validation Accuracy:\", val_accuracy)\n",
        "  wandb.log({'val_accuracy': val_accuracy})\n",
        "  wandb.run.name = run_name\n",
        "  wandb.run.save()\n",
        "  wandb.run.finish()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7e98d39eeabf49cf987ee0e03720b623",
            "d085d929172b44b89cd9a3530b524bce",
            "ececac51dc374527b5f888dee33bc6b2",
            "d4a76b4ac2a84401aa23ae49ebb950d7",
            "bbd65784fa044b378d34ebd52ab7e6b3",
            "fdcf7b2f111744afa746c32ab70569f8",
            "0917af2c249348d4adc044dd4d846bfc",
            "c868db45946e4cd19690be7f578ddf60",
            "39efe5bf814d4ac9a9eb44e7ba954067",
            "396c3a420cd6472a83fddd3a19404c06",
            "f42913d9667e4bd3a8727a4dd925b216",
            "029762c2924a4bf0b75b4ea484d1daf6",
            "b7bc7d78b51142dc82619cf97495fa34",
            "568d49fddf0c45fa871284488407b642",
            "2f9b77b6e32e4e9c9a68c981549331f4",
            "3f72215202294dea88aae51ce3604c9d",
            "fc239d9966ac494db6f0d1db04de5ec3",
            "bb1eaa88e51145a2808255b6d01ef842",
            "8edf34e1a5cb45fda750fc43b3d8298d",
            "cc350877fc824f6789e7401e5ab6f67f",
            "203be9aca1b74cedadd9c1713d9fe5d4",
            "6c6824f57652454eadb9be3a8ec0d64d",
            "5ce970cc487541aabe16ace40d926a0f",
            "b1a01a765494487bbc6d637fdfe5391f",
            "de62dc8ad8fc414fa483e775a12892e4",
            "c7806a71a5ce4a798f3772c0097f5a7c",
            "5b9266c2451e4bc38106caffce6d3e30",
            "1edbaf78237a4011b28ff475baf8a4a1",
            "4bc420bdd4744f98ad18758003bcc82c",
            "dfbdad51fb314dd4a779f0848947afb2",
            "c3abdc4f733d43f19ce86106b1b0075b",
            "2f0e5e705b9c48528a8c87f4b6eebc49",
            "6a9c84de610f42c4b6f0fb600d8260de",
            "60de6e91d360494b83dba9bfc93c8746",
            "8f66c352bd5540fd8e1350af52191eb9",
            "1177ab4887bd47f69bb9abf57ab0ac31",
            "202f9c452e604a07a5cea663a41e4160",
            "d76b9cd92fb14d3e9f857e0e0c07dfe5",
            "5b79935234c14e168ad9a4bdadcdec6f",
            "e30c5b410e784af4862febcb1192f4da"
          ]
        },
        "id": "oX-Qeh5jg-_A",
        "outputId": "8798fc04-a77d-4818-822b-59cbc03f7ee3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8unjpy35 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manandh\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_193239-8unjpy35</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/8unjpy35\" target=\"_blank\">quiet-sweep-76</a></strong> to <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1066/1066 [==============================] - 34s 26ms/step - loss: 0.7614 - accuracy: 0.7802\n",
            "Epoch 2/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.5101 - accuracy: 0.8451\n",
            "Epoch 3/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.4124 - accuracy: 0.8726\n",
            "Epoch 4/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.3330 - accuracy: 0.8953\n",
            "Epoch 5/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.2444 - accuracy: 0.9238\n",
            "Epoch 6/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.1791 - accuracy: 0.9447\n",
            "Epoch 7/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.1295 - accuracy: 0.9606\n",
            "Epoch 8/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0988 - accuracy: 0.9702\n",
            "Epoch 9/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0791 - accuracy: 0.9762\n",
            "Epoch 10/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0648 - accuracy: 0.9805\n",
            "Epoch 11/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0548 - accuracy: 0.9836\n",
            "Epoch 12/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0472 - accuracy: 0.9857\n",
            "Epoch 13/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0411 - accuracy: 0.9875\n",
            "Epoch 14/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0365 - accuracy: 0.9888\n",
            "Epoch 15/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0329 - accuracy: 0.9899\n",
            "Epoch 16/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0298 - accuracy: 0.9908\n",
            "Epoch 17/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0273 - accuracy: 0.9916\n",
            "Epoch 18/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0252 - accuracy: 0.9922\n",
            "Epoch 19/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0235 - accuracy: 0.9927\n",
            "Epoch 20/20\n",
            "1066/1066 [==============================] - 27s 26ms/step - loss: 0.0222 - accuracy: 0.9931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 12.701435687078817\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e98d39eeabf49cf987ee0e03720b623",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>12.70144</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">quiet-sweep-76</strong>: <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/8unjpy35\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/8unjpy35</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220502_193239-8unjpy35/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u6apf3ma with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_210015-u6apf3ma</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/u6apf3ma\" target=\"_blank\">swept-sweep-77</a></strong> to <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1066/1066 [==============================] - 26s 16ms/step - loss: 0.8590 - accuracy: 0.7565 - _timestamp: 1651525247.0000 - _runtime: 32.0000\n",
            "Epoch 2/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.6453 - accuracy: 0.8104 - _timestamp: 1651525264.0000 - _runtime: 49.0000\n",
            "Epoch 3/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.5604 - accuracy: 0.8357 - _timestamp: 1651525281.0000 - _runtime: 66.0000\n",
            "Epoch 4/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.5035 - accuracy: 0.8513 - _timestamp: 1651525299.0000 - _runtime: 84.0000\n",
            "Epoch 5/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.4580 - accuracy: 0.8649 - _timestamp: 1651525316.0000 - _runtime: 101.0000\n",
            "Epoch 6/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.4219 - accuracy: 0.8754 - _timestamp: 1651525333.0000 - _runtime: 118.0000\n",
            "Epoch 7/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.3915 - accuracy: 0.8843 - _timestamp: 1651525349.0000 - _runtime: 134.0000\n",
            "Epoch 8/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.3658 - accuracy: 0.8919 - _timestamp: 1651525366.0000 - _runtime: 151.0000\n",
            "Epoch 9/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.3427 - accuracy: 0.8991 - _timestamp: 1651525383.0000 - _runtime: 168.0000\n",
            "Epoch 10/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.3218 - accuracy: 0.9054 - _timestamp: 1651525400.0000 - _runtime: 185.0000\n",
            "Epoch 11/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.3057 - accuracy: 0.9099 - _timestamp: 1651525417.0000 - _runtime: 202.0000\n",
            "Epoch 12/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2926 - accuracy: 0.9140 - _timestamp: 1651525434.0000 - _runtime: 219.0000\n",
            "Epoch 13/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2818 - accuracy: 0.9172 - _timestamp: 1651525451.0000 - _runtime: 236.0000\n",
            "Epoch 14/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2717 - accuracy: 0.9205 - _timestamp: 1651525468.0000 - _runtime: 253.0000\n",
            "Epoch 15/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2628 - accuracy: 0.9233 - _timestamp: 1651525485.0000 - _runtime: 270.0000\n",
            "Epoch 16/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2551 - accuracy: 0.9255 - _timestamp: 1651525502.0000 - _runtime: 287.0000\n",
            "Epoch 17/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2482 - accuracy: 0.9276 - _timestamp: 1651525520.0000 - _runtime: 305.0000\n",
            "Epoch 18/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2411 - accuracy: 0.9298 - _timestamp: 1651525537.0000 - _runtime: 322.0000\n",
            "Epoch 19/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2342 - accuracy: 0.9320 - _timestamp: 1651525554.0000 - _runtime: 339.0000\n",
            "Epoch 20/20\n",
            "1066/1066 [==============================] - 17s 16ms/step - loss: 0.2278 - accuracy: 0.9341 - _timestamp: 1651525571.0000 - _runtime: 356.0000\n",
            "Validation Accuracy: 23.893934954585408\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39efe5bf814d4ac9a9eb44e7ba954067",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.93414</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.22777</td></tr><tr><td>val_accuracy</td><td>23.89393</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">swept-sweep-77</strong>: <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/u6apf3ma\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/u6apf3ma</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220502_210015-u6apf3ma/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zydnwy8a with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_221114-zydnwy8a</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/zydnwy8a\" target=\"_blank\">desert-sweep-78</a></strong> to <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1066/1066 [==============================] - 33s 26ms/step - loss: 0.7102 - accuracy: 0.7942\n",
            "Epoch 2/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.4345 - accuracy: 0.8669\n",
            "Epoch 3/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.3144 - accuracy: 0.9021\n",
            "Epoch 4/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.2166 - accuracy: 0.9326\n",
            "Epoch 5/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.1515 - accuracy: 0.9533\n",
            "Epoch 6/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.1100 - accuracy: 0.9664\n",
            "Epoch 7/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0848 - accuracy: 0.9743\n",
            "Epoch 8/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0677 - accuracy: 0.9795\n",
            "Epoch 9/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0553 - accuracy: 0.9831\n",
            "Epoch 10/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0464 - accuracy: 0.9860\n",
            "Epoch 11/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0402 - accuracy: 0.9877\n",
            "Epoch 12/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0352 - accuracy: 0.9892\n",
            "Epoch 13/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0316 - accuracy: 0.9903\n",
            "Epoch 14/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0285 - accuracy: 0.9912\n",
            "Epoch 15/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0260 - accuracy: 0.9920\n",
            "Epoch 16/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0241 - accuracy: 0.9925\n",
            "Epoch 17/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0228 - accuracy: 0.9930\n",
            "Epoch 18/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0212 - accuracy: 0.9934\n",
            "Epoch 19/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0202 - accuracy: 0.9937\n",
            "Epoch 20/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0193 - accuracy: 0.9940\n",
            "Epoch 21/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0186 - accuracy: 0.9942\n",
            "Epoch 22/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0179 - accuracy: 0.9945\n",
            "Epoch 23/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0173 - accuracy: 0.9946\n",
            "Epoch 24/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0168 - accuracy: 0.9947\n",
            "Epoch 25/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0163 - accuracy: 0.9949\n",
            "Epoch 26/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0157 - accuracy: 0.9951\n",
            "Epoch 27/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0155 - accuracy: 0.9952\n",
            "Epoch 28/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0151 - accuracy: 0.9953\n",
            "Epoch 29/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0148 - accuracy: 0.9954\n",
            "Epoch 30/30\n",
            "1066/1066 [==============================] - 28s 26ms/step - loss: 0.0146 - accuracy: 0.9955\n",
            "Validation Accuracy: 7.588631702314679\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc239d9966ac494db6f0d1db04de5ec3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>7.58863</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">desert-sweep-78</strong>: <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/zydnwy8a\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/zydnwy8a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220502_221114-zydnwy8a/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iz740uz2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220502_234141-iz740uz2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/iz740uz2\" target=\"_blank\">sage-sweep-79</a></strong> to <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embed done\n",
            "Starting 2nd\n",
            "Ending 2nd\n",
            "Epoch 1/20\n",
            "1066/1066 [==============================] - 120s 109ms/step - loss: 0.8028 - accuracy: 0.7798 - _timestamp: 1651535026.0000 - _runtime: 125.0000\n",
            "Epoch 2/20\n",
            "1066/1066 [==============================] - 118s 111ms/step - loss: 0.6264 - accuracy: 0.8178 - _timestamp: 1651535144.0000 - _runtime: 243.0000\n",
            "Epoch 3/20\n",
            "1066/1066 [==============================] - 119s 111ms/step - loss: 0.5924 - accuracy: 0.8271 - _timestamp: 1651535263.0000 - _runtime: 362.0000\n",
            "Epoch 4/20\n",
            "1066/1066 [==============================] - 118s 111ms/step - loss: 0.5723 - accuracy: 0.8329 - _timestamp: 1651535381.0000 - _runtime: 480.0000\n",
            "Epoch 5/20\n",
            "1066/1066 [==============================] - 119s 111ms/step - loss: 0.5580 - accuracy: 0.8366 - _timestamp: 1651535500.0000 - _runtime: 599.0000\n",
            "Epoch 6/20\n",
            "1066/1066 [==============================] - 119s 112ms/step - loss: 0.5467 - accuracy: 0.8398 - _timestamp: 1651535619.0000 - _runtime: 718.0000\n",
            "Epoch 7/20\n",
            "1066/1066 [==============================] - 119s 112ms/step - loss: 0.5375 - accuracy: 0.8421 - _timestamp: 1651535738.0000 - _runtime: 837.0000\n",
            "Epoch 8/20\n",
            "1066/1066 [==============================] - 119s 112ms/step - loss: 0.5298 - accuracy: 0.8440 - _timestamp: 1651535857.0000 - _runtime: 956.0000\n",
            "Epoch 9/20\n",
            "1066/1066 [==============================] - 119s 111ms/step - loss: 0.5236 - accuracy: 0.8458 - _timestamp: 1651535976.0000 - _runtime: 1075.0000\n",
            "Epoch 10/20\n",
            "1066/1066 [==============================] - 118s 111ms/step - loss: 0.5181 - accuracy: 0.8475 - _timestamp: 1651536095.0000 - _runtime: 1194.0000\n",
            "Epoch 11/20\n",
            "1066/1066 [==============================] - 118s 111ms/step - loss: 0.5139 - accuracy: 0.8484 - _timestamp: 1651536213.0000 - _runtime: 1312.0000\n",
            "Epoch 12/20\n",
            "1066/1066 [==============================] - 118s 111ms/step - loss: 0.5100 - accuracy: 0.8494 - _timestamp: 1651536331.0000 - _runtime: 1430.0000\n",
            "Epoch 13/20\n",
            "1066/1066 [==============================] - 118s 111ms/step - loss: 0.5066 - accuracy: 0.8503 - _timestamp: 1651536450.0000 - _runtime: 1549.0000\n",
            "Epoch 14/20\n",
            "1066/1066 [==============================] - 119s 111ms/step - loss: 0.5035 - accuracy: 0.8511 - _timestamp: 1651536568.0000 - _runtime: 1667.0000\n",
            "Epoch 15/20\n",
            "1066/1066 [==============================] - 119s 112ms/step - loss: 0.5009 - accuracy: 0.8516 - _timestamp: 1651536687.0000 - _runtime: 1786.0000\n",
            "Epoch 16/20\n",
            "1066/1066 [==============================] - 119s 112ms/step - loss: 0.4985 - accuracy: 0.8526 - _timestamp: 1651536806.0000 - _runtime: 1905.0000\n",
            "Epoch 17/20\n",
            "1066/1066 [==============================] - 119s 111ms/step - loss: 0.4956 - accuracy: 0.8531 - _timestamp: 1651536925.0000 - _runtime: 2024.0000\n",
            "Epoch 18/20\n",
            "1066/1066 [==============================] - 119s 112ms/step - loss: 0.4939 - accuracy: 0.8537 - _timestamp: 1651537044.0000 - _runtime: 2143.0000\n",
            "Epoch 19/20\n",
            "1066/1066 [==============================] - 119s 111ms/step - loss: 0.4921 - accuracy: 0.8540 - _timestamp: 1651537163.0000 - _runtime: 2262.0000\n",
            "Epoch 20/20\n",
            "1066/1066 [==============================] - 118s 111ms/step - loss: 0.4901 - accuracy: 0.8547 - _timestamp: 1651537281.0000 - _runtime: 2380.0000\n",
            "Validation Accuracy: 0.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de62dc8ad8fc414fa483e775a12892e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▅▆▆▇▇▇▇▇▇█████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85468</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.49006</td></tr><tr><td>val_accuracy</td><td>0.0</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">sage-sweep-79</strong>: <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/iz740uz2\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/iz740uz2</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220502_234141-iz740uz2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uzrsug3u with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220503_012431-uzrsug3u</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/uzrsug3u\" target=\"_blank\">dry-sweep-80</a></strong> to <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1066/1066 [==============================] - 43s 33ms/step - loss: 0.7961 - accuracy: 0.7715\n",
            "Epoch 2/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.4867 - accuracy: 0.8534\n",
            "Epoch 3/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.3543 - accuracy: 0.8904\n",
            "Epoch 4/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.2581 - accuracy: 0.9188\n",
            "Epoch 5/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.1713 - accuracy: 0.9466\n",
            "Epoch 6/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.1116 - accuracy: 0.9657\n",
            "Epoch 7/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0783 - accuracy: 0.9763\n",
            "Epoch 8/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0592 - accuracy: 0.9822\n",
            "Epoch 9/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0469 - accuracy: 0.9858\n",
            "Epoch 10/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0385 - accuracy: 0.9885\n",
            "Epoch 11/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0326 - accuracy: 0.9902\n",
            "Epoch 12/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0281 - accuracy: 0.9916\n",
            "Epoch 13/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0248 - accuracy: 0.9926\n",
            "Epoch 14/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0222 - accuracy: 0.9934\n",
            "Epoch 15/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0201 - accuracy: 0.9940\n",
            "Epoch 16/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0186 - accuracy: 0.9945\n",
            "Epoch 17/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0173 - accuracy: 0.9949\n",
            "Epoch 18/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0161 - accuracy: 0.9953\n",
            "Epoch 19/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0153 - accuracy: 0.9955\n",
            "Epoch 20/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0145 - accuracy: 0.9958\n",
            "Epoch 21/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0139 - accuracy: 0.9960\n",
            "Epoch 22/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0135 - accuracy: 0.9961\n",
            "Epoch 23/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0129 - accuracy: 0.9963\n",
            "Epoch 24/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0125 - accuracy: 0.9964\n",
            "Epoch 25/25\n",
            "1066/1066 [==============================] - 35s 33ms/step - loss: 0.0123 - accuracy: 0.9965\n",
            "Validation Accuracy: 8.54087313214181\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a9c84de610f42c4b6f0fb600d8260de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>8.54087</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">dry-sweep-80</strong>: <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/uzrsug3u\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/uzrsug3u</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220503_012431-uzrsug3u/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: va0p15cl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220503_031028-va0p15cl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/runs/va0p15cl\" target=\"_blank\">rose-sweep-81</a></strong> to <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv\" target=\"_blank\">https://wandb.ai/anandh/CS6910_Assignment3_S2S/sweeps/5y0u4iyv</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1066/1066 [==============================] - 66s 52ms/step - loss: 0.7915 - accuracy: 0.7733\n",
            "Epoch 2/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.3504 - accuracy: 0.8963\n",
            "Epoch 3/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.1581 - accuracy: 0.9555\n",
            "Epoch 4/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0956 - accuracy: 0.9735\n",
            "Epoch 5/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0671 - accuracy: 0.9813\n",
            "Epoch 6/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0510 - accuracy: 0.9856\n",
            "Epoch 7/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0402 - accuracy: 0.9884\n",
            "Epoch 8/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0335 - accuracy: 0.9902\n",
            "Epoch 9/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0286 - accuracy: 0.9915\n",
            "Epoch 10/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0250 - accuracy: 0.9925\n",
            "Epoch 11/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0221 - accuracy: 0.9933\n",
            "Epoch 12/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0201 - accuracy: 0.9940\n",
            "Epoch 13/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0185 - accuracy: 0.9944\n",
            "Epoch 14/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0175 - accuracy: 0.9947\n",
            "Epoch 15/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0165 - accuracy: 0.9950\n",
            "Epoch 16/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0156 - accuracy: 0.9952\n",
            "Epoch 17/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0150 - accuracy: 0.9955\n",
            "Epoch 18/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0145 - accuracy: 0.9956\n",
            "Epoch 19/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0140 - accuracy: 0.9957\n",
            "Epoch 20/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0135 - accuracy: 0.9959\n",
            "Epoch 21/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0132 - accuracy: 0.9960\n",
            "Epoch 22/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0129 - accuracy: 0.9961\n",
            "Epoch 23/30\n",
            "1066/1066 [==============================] - 55s 51ms/step - loss: 0.0127 - accuracy: 0.9962\n",
            "Epoch 24/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0124 - accuracy: 0.9963\n",
            "Epoch 25/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0121 - accuracy: 0.9963\n",
            "Epoch 26/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0118 - accuracy: 0.9963\n",
            "Epoch 27/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0117 - accuracy: 0.9964\n",
            "Epoch 28/30\n",
            "1066/1066 [==============================] - 55s 52ms/step - loss: 0.0116 - accuracy: 0.9965\n",
            "Epoch 29/30\n",
            "1066/1066 [==============================] - 55s 51ms/step - loss: 0.0115 - accuracy: 0.9965\n",
            "Epoch 30/30\n",
            "1066/1066 [==============================] - 54s 50ms/step - loss: 0.0111 - accuracy: 0.9966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "# run sweeps\n",
        "sweep_config = {\n",
        "    'method': 'bayes',  # grid, random\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'embedding_size': {\n",
        "            'values': [64,128,256]\n",
        "        },\n",
        "        'num_encoder_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'num_decoder_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'latent_dimension': {\n",
        "            'values': [64, 256, 512]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['RNN', 'GRU', 'LSTM']\n",
        "        },                             \n",
        "        'dropout': {\n",
        "            'values': [0.3,0.4,0.5,0.0,0.2]\n",
        "        },\n",
        "        'epochs': {\n",
        "            'values': [25,20,30]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "#sweep_id = wandb.sweep(sweep_config,entity=\"anandh\" ,project=\"CS6910_Assignment3_S2S\")\n",
        "# wandb.agent(sweep_id, fit, count=10)\n",
        "sweep_id=\"5y0u4iyv\"\n",
        "wandb.agent(sweep_id, fit, entity=\"anandh\", project = \"CS6910_Assignment3_S2S\", count = 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxkQNHxQ1IFo",
        "outputId": "e9f0b13f-ad9f-4d26-a591-d6383724ae21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1066/1066 [==============================] - 27s 19ms/step - loss: 0.7256 - accuracy: 0.7928\n",
            "Epoch 2/2\n",
            "1066/1066 [==============================] - 20s 19ms/step - loss: 0.2887 - accuracy: 0.9155\n",
            "Validation accuracy:  21.725754468209786\n"
          ]
        }
      ],
      "source": [
        "#####\n",
        "encoder_model, decoder_model=seq2seq(256, num_encoder_tokens,num_decoder_tokens,\n",
        "                2, 3,latent_dim,\n",
        "                'LSTM', target_token_index, max_decoder_seq_length,\n",
        "                reverse_target_char_index, 0.2,encoder_input_data, decoder_input_data,\n",
        "                decoder_target_data,batch_size)\n",
        "\n",
        "val_accuracy= accuracy(val_encoder_input_data, val_target_texts,3,encoder_model,decoder_model)\n",
        "print('Validation accuracy: ', val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pm3d0IB5_3K"
      },
      "outputs": [],
      "source": [
        "def beam_search(input_seq,encoder_model,decoder_model, beam_size,n_decoder_layers,cell_type):\n",
        "        sequences = [([target_token_index[\"\\t\"]], 0.0)]\n",
        "        # Encode the input as state vectors.\n",
        "        states_value = [[encoder_model.predict(input_seq)]*n_decoder_layers]\n",
        "\n",
        "        stop_condition = False\n",
        "        t = 0\n",
        "        while not stop_condition:\n",
        "            all_seq = list()\n",
        "            char_sequences = []\n",
        "            for seq, score in sequences:\n",
        "                char_seq = ''\n",
        "                for index in seq:\n",
        "                    char_seq += reverse_target_char_index[index]\n",
        "                char_sequences.append((char_seq, score))\n",
        "            #print('at time ', t, char_sequences)\n",
        "            t += 1\n",
        "            for i in range(len(sequences)):\n",
        "                seq, score = sequences[i]\n",
        "                if seq[-1] == target_token_index[\"\\n\"] or seq[-1] == target_token_index[\" \"]:\n",
        "                    all_seq.append((seq, score))\n",
        "                    continue\n",
        "                target_seq = np.zeros((1, 1))\n",
        "                target_seq[0, 0] = seq[-1]\n",
        "                # print('target seq', seq[-1], self.reverse_target_char_index[seq[-1]])\n",
        "                if cell_type is not None and (cell_type.lower() == 'rnn' or cell_type.lower() == 'gru'):\n",
        "                    temp = decoder_model.predict([target_seq] + [states_value[i]])\n",
        "                    output_tokens, temp_states = temp[0], temp[1:]\n",
        "                else:\n",
        "                    temp = decoder_model.predict([target_seq] + states_value[i] )\n",
        "                    output_tokens, temp_states = temp[0], temp[1:]\n",
        "\n",
        "                if t == 1:\n",
        "                    states_value = [temp_states] * beam_size\n",
        "                else:\n",
        "                    states_value[i] = temp_states\n",
        "\n",
        "                for j in range(len(output_tokens[0, -1, :])):\n",
        "                    candidate = (seq + [j], score - math.log(output_tokens[0, -1, j]))\n",
        "                    all_seq.append(candidate)\n",
        "\n",
        "                # Exit condition: either hit max length\n",
        "                # or find stop character.\n",
        "                sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "                sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "                # print('prob', output_tokens[0, -1, :])\n",
        "                # print('sampledchar ', sampled_char)\n",
        "\n",
        "            sorted_by_prob = sorted(all_seq, key=lambda tup: tup[1])\n",
        "\n",
        "            # print all possible sequences\n",
        "            char_sequences = []\n",
        "            for seq, score in sequences:\n",
        "                char_seq = ''\n",
        "                for index in seq:\n",
        "                    char_seq += reverse_target_char_index[index]\n",
        "                char_sequences.append((char_seq, score))\n",
        "            # print('Printing all sequences')\n",
        "            # print(char_sequences)\n",
        "\n",
        "            # select the top k sequences\n",
        "            sequences = sorted_by_prob[:beam_size]\n",
        "            if t > max_decoder_seq_length:\n",
        "                stop_condition = True\n",
        "            # if every sequence has predicted \\n we should stop\n",
        "            all_seq_ended = True\n",
        "            for seq, _ in sequences:\n",
        "                if seq[-1] != target_token_index[\"\\n\"]:\n",
        "                    all_seq_ended = False\n",
        "                    break\n",
        "            if all_seq_ended:\n",
        "                stop_condition = True\n",
        "        # create character out of indexes\n",
        "        char_sequences = []\n",
        "        for seq, score in sequences:\n",
        "            char_seq = ''\n",
        "            for index in seq:\n",
        "                char_seq += reverse_target_char_index[index]\n",
        "            char_sequences.append((char_seq, score))\n",
        "        return char_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx6uQIOe1gJo",
        "outputId": "60e58a8e-1da0-4f48-aa27-d1204f7fd10f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1066/1066 [==============================] - 36s 25ms/step - loss: 0.6057 - accuracy: 0.8263\n",
            "Epoch 2/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.2378 - accuracy: 0.9320\n",
            "Epoch 3/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.1513 - accuracy: 0.9574\n",
            "Epoch 4/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.1188 - accuracy: 0.9666\n",
            "Epoch 5/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.1010 - accuracy: 0.9716\n",
            "Epoch 6/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0896 - accuracy: 0.9747\n",
            "Epoch 7/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0811 - accuracy: 0.9768\n",
            "Epoch 8/25\n",
            "1066/1066 [==============================] - 26s 24ms/step - loss: 0.0747 - accuracy: 0.9786\n",
            "Epoch 9/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0697 - accuracy: 0.9797\n",
            "Epoch 10/25\n",
            "1066/1066 [==============================] - 26s 24ms/step - loss: 0.0661 - accuracy: 0.9809\n",
            "Epoch 11/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0628 - accuracy: 0.9817\n",
            "Epoch 12/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0599 - accuracy: 0.9825\n",
            "Epoch 13/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0578 - accuracy: 0.9829\n",
            "Epoch 14/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0559 - accuracy: 0.9834\n",
            "Epoch 15/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0543 - accuracy: 0.9837\n",
            "Epoch 16/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0529 - accuracy: 0.9842\n",
            "Epoch 17/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0515 - accuracy: 0.9845\n",
            "Epoch 18/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0504 - accuracy: 0.9848\n",
            "Epoch 19/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0495 - accuracy: 0.9851\n",
            "Epoch 20/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0483 - accuracy: 0.9853\n",
            "Epoch 21/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0479 - accuracy: 0.9854\n",
            "Epoch 22/25\n",
            "1066/1066 [==============================] - 26s 24ms/step - loss: 0.0472 - accuracy: 0.9856\n",
            "Epoch 23/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0464 - accuracy: 0.9858\n",
            "Epoch 24/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0456 - accuracy: 0.9861\n",
            "Epoch 25/25\n",
            "1066/1066 [==============================] - 26s 25ms/step - loss: 0.0451 - accuracy: 0.9862\n",
            "Reading test data\n",
            "Calculating test accuracy\n",
            "Test accuracy  {1: 49.04560687745884, 2: 49.147603089028124, 3: 49.16217397639516}\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0035bdff-05fe-4df3-b48b-37e5ecd52aee\", \"predictions_1.csv\", 446434)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_f2a3ed8a-11b3-4640-b7a2-ce705ba9bd00\", \"predictions_2.csv\", 445720)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_15402eb8-f2e2-4135-a965-c48cab0dda8f\", \"predictions_3.csv\", 445561)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoder_model, decoder_model=seq2seq(embedding_size, num_encoder_tokens,num_decoder_tokens,n_encoder_layers, n_decoder_layers,latent_dimension,\n",
        "                cell_type, target_token_index, max_decoder_seq_length,reverse_target_char_index, dropout ,encoder_input_data, decoder_input_data,\n",
        "                decoder_target_data,batch_size,epochs)\n",
        "# compute test accuracy\n",
        "print('Reading test data')\n",
        "test_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\"\n",
        "# open and save the files to lists\n",
        "with open(test_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_lines = f.read().split(\"\\n\")\n",
        "# popping the last element of all the lists since it is empty character\n",
        "test_lines.pop()\n",
        "# embedding test\n",
        "# for test data, almost same\n",
        "test_input_texts = []\n",
        "test_target_texts = []\n",
        "for line in test_lines[: (len(test_lines) - 1)]:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    test_input_texts.append(input_text)\n",
        "    test_target_texts.append(target_text)\n",
        "test_max_encoder_seq_length = max([len(txt) for txt in test_input_texts])\n",
        "test_max_decoder_seq_length = max([len(txt) for txt in test_target_texts])\n",
        "test_encoder_input_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "test_decoder_input_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "test_decoder_target_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(test_input_texts, test_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        test_encoder_input_data[i, t] = input_token_index[char]\n",
        "    test_encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        test_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            test_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    test_decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "    test_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "print('Calculating test accuracy')\n",
        "test_accuracy = {}\n",
        "for beamSize in range(1,4):\n",
        "  df = pd.DataFrame(columns=['Source', 'Predictions', 'GroundTruth'])\n",
        "  n_correct = 0\n",
        "  n_total = 0\n",
        "  for seq_index in range(len(test_encoder_input_data)):\n",
        "      decoded_sentence = beam_search(test_encoder_input_data[seq_index:seq_index+1],encoder_model,decoder_model,beamSize,n_decoder_layers,cell_type)\n",
        "\n",
        "      if test_target_texts[seq_index].strip() == decoded_sentence[0][0].strip():\n",
        "          n_correct += 1\n",
        "\n",
        "      n_total += 1\n",
        "      row = {}\n",
        "      row['SourceText'] = test_input_texts[seq_index].strip()\n",
        "      row['GroundTruth'] = test_target_texts[seq_index].strip()\n",
        "      row['Prediction'] = decoded_sentence[0][0].strip()\n",
        "      df = df.append(row, ignore_index=True)\n",
        "  df.to_csv('predictions_'+str(beamSize)+'.csv', index=False)  \n",
        "  test_accuracy[beamSize] = (n_correct * 100.0 / n_total)\n",
        "print('Test accuracy ', test_accuracy)\n",
        "\n",
        "import time\n",
        "for beamSize in range(1,4):\n",
        "  files.download('predictions_'+str(beamSize)+'.csv')\n",
        "  time.sleep(30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "029762c2924a4bf0b75b4ea484d1daf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0917af2c249348d4adc044dd4d846bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1177ab4887bd47f69bb9abf57ab0ac31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1edbaf78237a4011b28ff475baf8a4a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202f9c452e604a07a5cea663a41e4160": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203be9aca1b74cedadd9c1713d9fe5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0e5e705b9c48528a8c87f4b6eebc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f9b77b6e32e4e9c9a68c981549331f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396c3a420cd6472a83fddd3a19404c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7bc7d78b51142dc82619cf97495fa34",
            "placeholder": "​",
            "style": "IPY_MODEL_568d49fddf0c45fa871284488407b642",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "39efe5bf814d4ac9a9eb44e7ba954067": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_396c3a420cd6472a83fddd3a19404c06",
              "IPY_MODEL_f42913d9667e4bd3a8727a4dd925b216"
            ],
            "layout": "IPY_MODEL_029762c2924a4bf0b75b4ea484d1daf6"
          }
        },
        "3f72215202294dea88aae51ce3604c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bc420bdd4744f98ad18758003bcc82c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568d49fddf0c45fa871284488407b642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b79935234c14e168ad9a4bdadcdec6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9266c2451e4bc38106caffce6d3e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3abdc4f733d43f19ce86106b1b0075b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f0e5e705b9c48528a8c87f4b6eebc49",
            "value": 1
          }
        },
        "5ce970cc487541aabe16ace40d926a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60de6e91d360494b83dba9bfc93c8746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_202f9c452e604a07a5cea663a41e4160",
            "placeholder": "​",
            "style": "IPY_MODEL_d76b9cd92fb14d3e9f857e0e0c07dfe5",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "6a9c84de610f42c4b6f0fb600d8260de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60de6e91d360494b83dba9bfc93c8746",
              "IPY_MODEL_8f66c352bd5540fd8e1350af52191eb9"
            ],
            "layout": "IPY_MODEL_1177ab4887bd47f69bb9abf57ab0ac31"
          }
        },
        "6c6824f57652454eadb9be3a8ec0d64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e98d39eeabf49cf987ee0e03720b623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d085d929172b44b89cd9a3530b524bce",
              "IPY_MODEL_ececac51dc374527b5f888dee33bc6b2"
            ],
            "layout": "IPY_MODEL_d4a76b4ac2a84401aa23ae49ebb950d7"
          }
        },
        "8edf34e1a5cb45fda750fc43b3d8298d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce970cc487541aabe16ace40d926a0f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1a01a765494487bbc6d637fdfe5391f",
            "value": 1
          }
        },
        "8f66c352bd5540fd8e1350af52191eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b79935234c14e168ad9a4bdadcdec6f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e30c5b410e784af4862febcb1192f4da",
            "value": 1
          }
        },
        "b1a01a765494487bbc6d637fdfe5391f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7bc7d78b51142dc82619cf97495fa34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb1eaa88e51145a2808255b6d01ef842": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_203be9aca1b74cedadd9c1713d9fe5d4",
            "placeholder": "​",
            "style": "IPY_MODEL_6c6824f57652454eadb9be3a8ec0d64d",
            "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "bbd65784fa044b378d34ebd52ab7e6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3abdc4f733d43f19ce86106b1b0075b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7806a71a5ce4a798f3772c0097f5a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc420bdd4744f98ad18758003bcc82c",
            "placeholder": "​",
            "style": "IPY_MODEL_dfbdad51fb314dd4a779f0848947afb2",
            "value": "0.014 MB of 0.014 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "c868db45946e4cd19690be7f578ddf60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc350877fc824f6789e7401e5ab6f67f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d085d929172b44b89cd9a3530b524bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd65784fa044b378d34ebd52ab7e6b3",
            "placeholder": "​",
            "style": "IPY_MODEL_fdcf7b2f111744afa746c32ab70569f8",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "d4a76b4ac2a84401aa23ae49ebb950d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76b9cd92fb14d3e9f857e0e0c07dfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de62dc8ad8fc414fa483e775a12892e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7806a71a5ce4a798f3772c0097f5a7c",
              "IPY_MODEL_5b9266c2451e4bc38106caffce6d3e30"
            ],
            "layout": "IPY_MODEL_1edbaf78237a4011b28ff475baf8a4a1"
          }
        },
        "dfbdad51fb314dd4a779f0848947afb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e30c5b410e784af4862febcb1192f4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ececac51dc374527b5f888dee33bc6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0917af2c249348d4adc044dd4d846bfc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c868db45946e4cd19690be7f578ddf60",
            "value": 1
          }
        },
        "f42913d9667e4bd3a8727a4dd925b216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9b77b6e32e4e9c9a68c981549331f4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f72215202294dea88aae51ce3604c9d",
            "value": 1
          }
        },
        "fc239d9966ac494db6f0d1db04de5ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb1eaa88e51145a2808255b6d01ef842",
              "IPY_MODEL_8edf34e1a5cb45fda750fc43b3d8298d"
            ],
            "layout": "IPY_MODEL_cc350877fc824f6789e7401e5ab6f67f"
          }
        },
        "fdcf7b2f111744afa746c32ab70569f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}