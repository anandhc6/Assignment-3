{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best_Attention.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO68gmxnMhFHDqkxPLQ5b/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandhc6/Assignment-3/blob/main/Best_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KhDxe46ViCCn"
      },
      "outputs": [],
      "source": [
        "#import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "from random import randrange \n",
        "#from google.colab import files\n",
        "import pandas as pd\n",
        "import random\n",
        "from tensorflow import keras\n",
        "#from keras import backend\n",
        "#from tensorflow.python.keras import layers\n",
        "\n",
        "#from tensorflow.python.keras.models import load_model\n",
        "#from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf 'dakshina_dataset_v1.0.tar'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zRhhFwXid4u",
        "outputId": "eaf8056b-9f32-42d7-e677-9b9c462cdd62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-06 12:27:10--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.4.128, 142.251.10.128, 142.251.12.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.4.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G  69.9MB/s    in 34s     \n",
            "\n",
            "2022-05-06 12:27:44 (57.1 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "#epochs = 10  # Number of epochs to train for.\n",
        "#latent_dim = 256  # Latent dimensionality of the encoding space. #hidden states hyperparameter\n",
        "# Path to the data txt file on disk.\n",
        "train_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
        "val_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
        "# open and save the files to lists\n",
        "with open(train_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_lines = f.read().split(\"\\n\")\n",
        "with open(val_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    val_lines = f.read().split(\"\\n\")\n",
        "# popping the last element of all the lists since it is empty character\n",
        "train_lines.pop()\n",
        "val_lines.pop()\n",
        "random.shuffle(train_lines)\n",
        "print(train_lines[0:2])\n"
      ],
      "metadata": {
        "id": "SQdGUuUTDj1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee529dd-7d81-4206-f755-9773e58ab9c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['சிற்பங்கள்\\tchirpangal\\t1', 'குறைபாடுகளை\\tkuraipaadukalai\\t1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding train model\n",
        "def embedding_train(train_lines):\n",
        "\n",
        "    input_texts = []\n",
        "    target_texts = []\n",
        "    input_characters = set()\n",
        "    target_characters = set()\n",
        "    # go through the train lines and split them into 3 and save input and target\n",
        "    for line in train_lines[: (len(train_lines) - 1)]:\n",
        "        # because we want english to devanagiri conversion\n",
        "        target_text, input_text, _ = line.split(\"\\t\")\n",
        "        # We use \"tab\" as the \"start sequence\" character\n",
        "        # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "        target_text = \"\\t\" + target_text + \"\\n\"\n",
        "        # append it to the main input texts list\n",
        "        input_texts.append(input_text)\n",
        "        # append it to the main target texts list\n",
        "        target_texts.append(target_text)\n",
        "        # to find the number of unique characters in both\n",
        "        for char in input_text:\n",
        "            if char not in input_characters:\n",
        "                input_characters.add(char)\n",
        "        for char in target_text:\n",
        "            if char not in target_characters:\n",
        "                target_characters.add(char)\n",
        "    # add the space character to both\n",
        "    input_characters.add(\" \")\n",
        "    target_characters.add(\" \")\n",
        "    # sort it\n",
        "    input_characters = sorted(list(input_characters))\n",
        "    target_characters = sorted(list(target_characters))\n",
        "    # find the number\n",
        "    num_encoder_tokens = len(input_characters)\n",
        "    num_decoder_tokens = len(target_characters)\n",
        "    # find the maximum length of input word and target word\n",
        "    max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "    max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "    \n",
        "    print(\"Number of samples:\", len(input_texts))\n",
        "    print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "    print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "    print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "    print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "    # create an index\n",
        "    input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "    target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "   \n",
        "    # create an 0 array for encoder input size of (input_texts,max_seqlen,tokens)\n",
        "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length), dtype=\"float32\")\n",
        "    # create decoder input\n",
        "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length), dtype=\"float32\")\n",
        "    # create decoder target\n",
        "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "    # for each sample convert it into character encoding i.e. if\n",
        "    # at that position a character is present then encode the index of that character there\n",
        "    # this is done for both encoder and decoder input data for further word embedding\n",
        "    # but target data is one hot encoded.\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t] = input_token_index[char]\n",
        "        # remaining positions set as empty space\n",
        "        encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "        # similarly do for decoder data\n",
        "        for t, char in enumerate(target_text):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            decoder_input_data[i, t] = target_token_index[char]\n",
        "            # check if t >0 since decoder targer data is ahead\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "        # append both the remaining positions of both the datas with empty space\n",
        "        decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "        decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "    return encoder_input_data,decoder_input_data,decoder_target_data,num_encoder_tokens,num_decoder_tokens,input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length\n"
      ],
      "metadata": {
        "id": "a5A1UcDHPN80"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding validation data\n",
        "# for validation data, almost same\n",
        "def embedding_val(val_lines,num_decoder_tokens,input_token_index,target_token_index):\n",
        "    val_input_texts = []\n",
        "    val_target_texts = []\n",
        "    \n",
        "    for line in val_lines[: (len(val_lines) - 1)]:\n",
        "        target_text, input_text, _ = line.split(\"\\t\")\n",
        "        # We use \"tab\" as the \"start sequence\" character\n",
        "        # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "        target_text = \"\\t\" + target_text + \"\\n\"\n",
        "        val_input_texts.append(input_text)\n",
        "        val_target_texts.append(target_text)\n",
        "    val_max_encoder_seq_length = max([len(txt) for txt in val_input_texts])\n",
        "    val_max_decoder_seq_length = max([len(txt) for txt in val_target_texts])\n",
        "    val_encoder_input_data = np.zeros(\n",
        "        (len(val_input_texts), val_max_encoder_seq_length), dtype=\"float32\")\n",
        "    val_decoder_input_data = np.zeros(\n",
        "        (len(val_input_texts), val_max_decoder_seq_length), dtype=\"float32\")\n",
        "    val_decoder_target_data = np.zeros(\n",
        "        (len(val_input_texts), val_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "    for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            val_encoder_input_data[i, t] = input_token_index[char]\n",
        "        val_encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "        for t, char in enumerate(target_text):\n",
        "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "            val_decoder_input_data[i, t] = target_token_index[char]\n",
        "            if t > 0:\n",
        "                # decoder_target_data will be ahead by one timestep\n",
        "                # and will not include the start character.\n",
        "                val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "        val_decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "        val_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "\n",
        "    return val_encoder_input_data,val_decoder_input_data,val_decoder_target_data,target_token_index,val_target_texts\n"
      ],
      "metadata": {
        "id": "Og_HtjQwPN81"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embedding data\n",
        "encoder_input_data,decoder_input_data,decoder_target_data,num_encoder_tokens,num_decoder_tokens,input_token_index,target_token_index,max_encoder_seq_length,max_decoder_seq_length = embedding_train(train_lines)\n",
        "val_encoder_input_data,val_decoder_input_data,val_decoder_target_data,target_token_index,val_target_texts = embedding_val(val_lines,num_decoder_tokens,input_token_index,target_token_index)\n",
        "\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "#reverse_target_char_index[0] = \"\\n\""
      ],
      "metadata": {
        "id": "SphcvHgrD6D2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffd64e92-8cce-4fc3-8a1c-7d96e6eaef54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 68217\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4_awjGcVVsdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "    \n",
        "    Credits to Tensorflow.org and https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.        \n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            #print(\"Started context\")\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "metadata": {
        "id": "yzqs1qYNQBqy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def seq2seq(embedding_size, n_encoder_tokens, n_decoder_tokens, n_encoder_layers,\n",
        "                 n_decoder_layers, latent_dimension, cell_type,\n",
        "                 target_token_index, max_decoder_seq_length, reverse_target_char_index,\n",
        "                 dropout,encoder_input_data, decoder_input_data,\n",
        "                decoder_target_data,\n",
        "                batch_size,epochs\n",
        "):\n",
        "  encoder_inputs = keras.Input(shape=(None,), name='encoder_input')\n",
        "  # word embedding layer\n",
        "  encoder = None\n",
        "  encoder_outputs = None\n",
        "  state_h = None\n",
        "  state_c = None\n",
        "  e_layer=n_encoder_layers\n",
        "\n",
        "  if cell_type==\"RNN\":\n",
        "    embed = tf.keras.layers.Embedding(input_dim=n_encoder_tokens, output_dim=embedding_size,\n",
        "                                             name='encoder_embedding')(encoder_inputs)\n",
        "\n",
        "    encoder = keras.layers.SimpleRNN(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                             name='encoder_hidden_1', dropout=dropout)\n",
        "    encoder_outputs, state_h = encoder(embed)\n",
        "\n",
        "    encoder_states = None\n",
        "    encoder_states = [state_h]\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), name='decoder_input')\n",
        "    embed_dec = tf.keras.layers.Embedding(n_decoder_tokens, embedding_size, name='decoder_embedding')(\n",
        "        decoder_inputs)\n",
        "    \n",
        "    # number of decoder layers\n",
        "    d_layer = n_decoder_layers\n",
        "    decoder = None\n",
        "    decoder = keras.layers.SimpleRNN(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                             name='decoder_hidden_1', dropout=dropout)\n",
        "        \n",
        "    # all decoders the initial state is encoder last state of last layer\n",
        "    decoder_outputs, _ = decoder(embed_dec, initial_state=encoder_states)\n",
        "    \n",
        "    attn_out, attn_states = AttentionLayer(name='attention_layer')([encoder_outputs, decoder_outputs])\n",
        "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "    # hidden = keras.layers.Dense(embedding_size, activation=\"relu\")\n",
        "    # hidden_outputs = hidden(decoder_concat_input)\n",
        "    #decoder_dense = keras.layers.Dense(n_decoder_tokens, activation=\"softmax\",name=\"dense_1\")\n",
        "    decoder_dense = tf.keras.layers.TimeDistributed(keras.layers.Dense(n_decoder_tokens, activation=\"softmax\",name=\"dense_1\"))\n",
        "    decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    model.compile(\n",
        "          optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
        "          metrics=['accuracy'])#, metrics=[my_metric]                 \n",
        "\n",
        "    model.fit(\n",
        "          [encoder_input_data, decoder_input_data],\n",
        "          decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          #callbacks=WandbCallback()\n",
        "      )\n",
        "    model.summary()\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc = model.get_layer(\n",
        "              'encoder_hidden_' + str(n_encoder_layers)).output\n",
        "    encoder_states = [encoder_outputs, state_h_enc]\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "    decoder_states_inputs = []\n",
        "    decoder_states = []\n",
        "    decoder_hidden_state = keras.Input(shape=(None,latent_dimension), name = \"input_4\")\n",
        "\n",
        "    for j in range(1, n_decoder_layers + 1):\n",
        "        decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "        current_states_inputs = [decoder_state_input_h]\n",
        "        decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "        decoder_outputs, state_h_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "        decoder_states += [state_h_dec]\n",
        "        decoder_states_inputs += current_states_inputs\n",
        "\n",
        "\n",
        "    attention_layer = model.get_layer('attention_layer')\n",
        "    #decoder_outputs_att = decoder_ouputs\n",
        "    attention_out, attention_states = attention_layer([decoder_hidden_state, decoder_outputs])\n",
        "\n",
        "    decoder_concat_inf = keras.layers.Concatenate(axis=-1, name='concat_layer_inf')([decoder_outputs, attention_out])\n",
        "    decoder_dense = model.get_layer(\"time_distributed_2\")\n",
        "    decoder_dense_outputs = decoder_dense(decoder_concat_inf)\n",
        "    # decoder_model = keras.Model(\n",
        "    #     [encoder_inputs, decoder_inputs] + decoder_states_inputs,[attention_states, decoder_dense_outputs] + decoder_states\n",
        "    # )\n",
        "    decoder_model=keras.Model([decoder_inputs]+[decoder_hidden_state,decoder_state_input_h],[decoder_dense_outputs]+decoder_states+[attention_states])\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "  elif cell_type==\"GRU\":\n",
        "    embed = tf.keras.layers.Embedding(input_dim=n_encoder_tokens, output_dim=embedding_size,\n",
        "                                             name='encoder_embedding')(encoder_inputs)\n",
        "    encoder = keras.layers.GRU(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                             name='encoder_hidden_1', dropout=dropout)\n",
        "    encoder_outputs, state_h = encoder(embed)\n",
        "   \n",
        "    encoder_states = None\n",
        "    encoder_states = [state_h]\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), name='decoder_input')\n",
        "    embed_dec = tf.keras.layers.Embedding(n_decoder_tokens, embedding_size, name='decoder_embedding')(\n",
        "        decoder_inputs)\n",
        "    # number of decoder layers\n",
        "    d_layer = n_decoder_layers\n",
        "    decoder = None\n",
        "    decoder = keras.layers.GRU(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                             name='decoder_hidden_1', dropout=dropout)\n",
        "    # all decoders the initial state is encoder last state of last layer\n",
        "    decoder_outputs, _ = decoder(embed_dec, initial_state=encoder_states)\n",
        "    attn_out, attn_states = AttentionLayer(name='attention_layer')([encoder_outputs, decoder_outputs])\n",
        "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "    decoder_dense = keras.layers.Dense(n_decoder_tokens, activation=\"softmax\", name='dense_1')\n",
        "    #decoder_dense = tf.keras.layers.TimeDistributed(keras.layers.Dense(n_decoder_tokens, activation=\"softmax\",name=\"dense_1\"))\n",
        "    decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    model.compile(\n",
        "          optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
        "          metrics=['accuracy'])#, metrics=[my_metric]                 \n",
        "\n",
        "    # earlystopping = EarlyStopping(\n",
        "    #     monitor=\"val_loss\", min_delta=0.01, patience=5, verbose=2, mode=\"min\")\n",
        "    \n",
        "    model.fit(\n",
        "          [encoder_input_data, decoder_input_data],\n",
        "          decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          #validation_data=([val_encoder_input_data, val_target_texts])\n",
        "\n",
        "          #callbacks=WandbCallback()\n",
        "      )\n",
        "    model.summary()\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc = model.get_layer(\n",
        "              'encoder_hidden_' + str(n_encoder_layers)).output\n",
        "    encoder_states = [encoder_outputs,state_h_enc]\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "    decoder_states_inputs = []\n",
        "    decoder_states = []\n",
        "    decoder_hidden_state = keras.Input(shape=(None,latent_dimension), name = \"input_4\")\n",
        "\n",
        "\n",
        "    for j in range(1, n_decoder_layers + 1):\n",
        "        decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "        current_states_inputs = [decoder_state_input_h]\n",
        "        decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "        decoder_outputs, state_h_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "        decoder_states += [state_h_dec]\n",
        "        decoder_states_inputs += current_states_inputs\n",
        "\n",
        "    attention_layer = model.get_layer('attention_layer')\n",
        "    #decoder_outputs_att = decoder_ouputs\n",
        "    attention_out, attention_states = attention_layer([decoder_hidden_state, decoder_outputs])\n",
        "    decoder_concat_inf = keras.layers.Concatenate(axis=-1, name='concat_layer_inf')([decoder_outputs, attention_out])\n",
        "\n",
        "    decoder_dense = model.get_layer('dense_1')\n",
        "    decoder_dense_outputs = decoder_dense(decoder_concat_inf)\n",
        "    decoder_model=keras.Model([decoder_inputs]+[decoder_hidden_state,decoder_state_input_h],[decoder_dense_outputs]+decoder_states+[attention_states])\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "\n",
        "\n",
        "  elif cell_type==\"LSTM\":\n",
        "    embed = tf.keras.layers.Embedding(input_dim=n_encoder_tokens, output_dim=embedding_size,\n",
        "                                             name='encoder_embedding')(encoder_inputs)\n",
        "    encoder = keras.layers.LSTM(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                             name='encoder_hidden_1', dropout=dropout)\n",
        "    encoder_outputs, state_h, state_c = encoder(embed)\n",
        "  \n",
        "    encoder_states = None\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None,), name='decoder_input')\n",
        "    embed_dec = tf.keras.layers.Embedding(n_decoder_tokens, embedding_size, name='decoder_embedding')(\n",
        "        decoder_inputs)\n",
        "    # number of decoder layers\n",
        "    d_layer = n_decoder_layers\n",
        "    decoder = None\n",
        "    decoder = keras.layers.LSTM(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                             name='decoder_hidden_1', dropout=dropout)\n",
        "    # all decoders the initial state is encoder last state of last layer\n",
        "    decoder_outputs, _,_ = decoder(embed_dec, initial_state=encoder_states)\n",
        "    attn_out, attn_states = AttentionLayer(name='attention_layer')([encoder_outputs, decoder_outputs])\n",
        "    decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "    decoder_dense = keras.layers.Dense(n_decoder_tokens, activation=\"softmax\", name='dense_1')\n",
        "    decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    model.compile(\n",
        "          optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",\n",
        "          metrics=['accuracy'])#, metrics=[my_metric]                 \n",
        "    \n",
        "    # earlystopping = EarlyStopping(\n",
        "    #     monitor=\"val_loss\", min_delta=0.01, patience=5, verbose=2, mode=\"min\")\n",
        "    \n",
        "    model.fit(\n",
        "          [encoder_input_data, decoder_input_data],\n",
        "          decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          #validation_data=[val_encoder_input_data, val_target_texts]\n",
        "          #callbacks=WandbCallback()\n",
        "      )\n",
        "    model.summary()\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.get_layer(\n",
        "              'encoder_hidden_' + str(n_encoder_layers)).output\n",
        "    encoder_states = [encoder_outputs,state_h_enc, state_c_enc]\n",
        "    encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "    decoder_states_inputs = []\n",
        "    decoder_states = []\n",
        "    decoder_hidden_state = keras.Input(shape=(None,latent_dimension), name = \"input_4\")\n",
        "\n",
        "    for j in range(1,n_decoder_layers + 1):\n",
        "        decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "        decoder_state_input_c = keras.Input(shape=(latent_dimension,))\n",
        "        current_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "        decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "        decoder_outputs_inf, state_h_dec, state_c_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "        decoder_states += [state_h_dec, state_c_dec]\n",
        "        decoder_states_inputs += current_states_inputs\n",
        "\n",
        "    attention_layer = model.get_layer('attention_layer')\n",
        "    #decoder_outputs_att = decoder_ouputs\n",
        "    attention_out, attention_states = attention_layer([decoder_hidden_state, decoder_outputs_inf])\n",
        "    decoder_concat_inf = keras.layers.Concatenate(axis=-1, name='concat_layer_inf')([decoder_outputs_inf, attention_out])\n",
        "\n",
        "    decoder_dense = model.get_layer('dense_1')\n",
        "    decoder_dense_outputs = decoder_dense(decoder_concat_inf)\n",
        "    # decoder_model = keras.Model(\n",
        "    #     [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "    # )\n",
        "    decoder_model=keras.Model([decoder_inputs]+[decoder_hidden_state,decoder_state_input_h,decoder_state_input_c],[decoder_dense_outputs]+decoder_states+[attention_states])\n",
        "\n",
        "    return encoder_model, decoder_model\n",
        "      "
      ],
      "metadata": {
        "id": "aLqfVhxah7U6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def decode_sequence(input_seq,n_decoder_layers,cell_type,encoder_model,decoder_model,latent_dimension):\n",
        "#             # Encode the input as state vectors.\n",
        "#             if cell_type=='LSTM':\n",
        "#               encoder_first_outputs,state_h,state_c= encoder_model.predict(input_seq)\n",
        "#               states_value=[state_h,state_c]\n",
        "#             else:\n",
        "#               encoder_first_outputs,states_value= encoder_model.predict(input_seq)\n",
        "\n",
        "#             # Generate empty target sequence of length 1.\n",
        "#             empty_seq = np.zeros((1, 1))\n",
        "#             empty_seq[0, 0] = target_token_index[\"\\t\"]\n",
        "#             target_seq = empty_seq\n",
        "\n",
        "#             # Sampling loop for a batch of sequences\n",
        "#             # (to simplify, here we assume a batch of size 1).\n",
        "#             stop_condition = False\n",
        "#             decoded_sentence = \"\"\n",
        "#             attention_weights = []\n",
        "#             while not stop_condition:\n",
        "#                 if cell_type == \"LSTM\":\n",
        "#                     output_tokens, h, c,attn = decoder_model.predict([target_seq, encoder_first_outputs] + states_value)\n",
        "#                 elif cell_type == \"RNN\" or cell_type == \"GRU\":\n",
        "#                     states_value = states_value[0].reshape((1, latent_dimension))\n",
        "#                     output_tokens, h ,attn= decoder_model.predict([target_seq] + [encoder_first_outputs] + [states_value])\n",
        "#                 #dec_ind = np.argmax(output_tokens, axis=-1)[0, 0]\n",
        "                \n",
        "#                 attention_weights.append(attn)\n",
        "#                 #print(attention_weights)\n",
        "#                 # print(\"1\")\n",
        "#                 # attention=np.array(attention_weights)\n",
        "#                 # print(attention.reshape(attention.shape[0],attention.shape[-1]))\n",
        "    \n",
        "#                 # Sample a token\n",
        "#                 sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "#                 sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "#                 decoded_sentence += sampled_char\n",
        "\n",
        "#                 # Exit condition: either hit max length\n",
        "#                 # or find stop character.\n",
        "#                 if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "#                     stop_condition = True\n",
        "\n",
        "#                 # Update the target sequence (of length 1).\n",
        "#                 target_seq = np.zeros((1, 1))\n",
        "#                 target_seq[0, 0]= sampled_token_index\n",
        "\n",
        "#                 # Update states\n",
        "#                 if cell_type == \"LSTM\":\n",
        "#                     states_value = [h, c]\n",
        "#                 elif cell_type == \"RNN\" or cell_type == \"GRU\":\n",
        "#                     states_value = [h]\n",
        "#             return decoded_sentence,attention_weights"
      ],
      "metadata": {
        "id": "6UunLBTyN_BT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rGiZKLN7eQ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Y1lIdwQZOkKY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "import ast\n",
        "\n",
        "def softmax(x):\n",
        "    denom = sum([np.exp(p) for p in x])\n",
        "    return [np.exp(p) / denom for p in x]\n",
        "\n",
        "def cstr(s, color = 'black'):\n",
        "    return \"<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:{}>{} </text>\".format(color, s)\n",
        "\n",
        "def get_clr(value, mode):\n",
        "    if(mode == 'l'):\n",
        "        colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8', '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8', '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f', '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "        value = int((value * 100) / 5)\n",
        "        return colors[value]\n",
        "    else:\n",
        "        # colors = ['#FFFFFF','#DFFFFF','#BFFFFF','#9FFFFF','#7FFFFF','#5FFFFF','#3FFFFF','#03FFFF','#00EFFF','#00DFFF','#00CFFF','#00BFFF','#00AFFF','#009FFF']\n",
        "        # factor = 0.07142857142857142\n",
        "        # color_index = int(value/factor)\n",
        "        # return colors[color_index]\n",
        "        colors = ['#ffffff', '#ecf7fb', '#daeff7', '#c7e7f3', '#b5dfef', '#a2d7eb', '#90cfe7', '#7dc7e3', '#6abfdf', '#58b7db', '#46afd7']\n",
        "        value = int((value * 100) / 10)\n",
        "        return colors[value]\n",
        "\n",
        "def visualize_c(dec_char, text_colours):\n",
        "    if (dec_char == \"<e>\"):\n",
        "      display(HTML(''.join([cstr(ti, color = ci) for ti, ci in text_colours]) + \" <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; \"))\n",
        "    else:\n",
        "      display(HTML(''.join([cstr(ti, color = ci) for ti, ci in text_colours]) + \" <b> &emsp; {}</b>  &emsp; &emsp; \".format(dec_char)))\n",
        "\n",
        "def visualize_l(dec_seq, prob):\n",
        "    text_colours = []\n",
        "\n",
        "    for c, p in zip(dec_seq, prob): \n",
        "        text = (c, get_clr(p, 'l'))\n",
        "        text_colours.append(text)\n",
        "    \n",
        "    display(HTML(''.join([cstr(ti, color = ci) for ti, ci in text_colours])))\n",
        "\n",
        "def visualize_connectivity(N):\n",
        "\n",
        "    # Reading from conv_vis file\n",
        "    with open(\"conn_vis.txt\", \"r\", encoding='utf-8') as filepointer:\n",
        "        \n",
        "        lines = filepointer.readlines()\n",
        "        #print(\"lines\",lines)\n",
        "        i = 0\n",
        "        words_visualized = 0\n",
        "\n",
        "        while i < len(lines) and  words_visualized< N:\n",
        "            line = lines[i]\n",
        "            #print(\"line:\",line)\n",
        "            if line[:4] == \"Next\":\n",
        "                words_visualized += 1\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            if line[:4] != \"Next\": \n",
        "                true_word, dec_char_len = line.split('\\t') \n",
        "                #print(len(true_word))\n",
        "                dec_word_len = int(dec_char_len)\n",
        "                i += 1\n",
        "\n",
        "                true_word_array = [c for c in true_word]\n",
        "                #print(true_word_array)\n",
        "\n",
        "                for j in range(dec_word_len):\n",
        "                    line = lines[i]\n",
        "                    #print(line)                   \n",
        "                    line = line.split('\\t')\n",
        "                    #print(line)\n",
        "  \n",
        "                    dec_char = line[0]\n",
        "                    text_colours = []\n",
        "\n",
        "                    prob = []\n",
        "                    for prob_index in range(1,len(true_word)+1) :\n",
        "                        print(prob_index)\n",
        "                        p = float(line[prob_index])\n",
        "                        prob.append(p)\n",
        "\n",
        "                    line = softmax(prob)\n",
        "\n",
        "                    \n",
        "                    for prob_index in range(len(true_word)) :\n",
        "                        p = float(line[prob_index])\n",
        "\n",
        "                        true_char = true_word_array[prob_index]\n",
        "                        text= (true_char, get_clr(p, 'c') )\n",
        "                        text_colours.append(text)\n",
        "\n",
        "                    visualize_c(dec_char, text_colours)\n",
        "            \n",
        "                    i += 1\n",
        "\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "def visualize_lstm(N, neuron):\n",
        "\n",
        "    for i in range(N):\n",
        "\n",
        "        file = open(\"lstm_vis_\" + str(i) + \".txt\", \"r\")\n",
        "        input_seq = file.readline()[:-1]\n",
        "        \n",
        "        dec_seq = []\n",
        "        prob = []\n",
        "\n",
        "        for line in file:\n",
        "            temp = line.split('\\t')\n",
        "            dec_seq.append(temp[0])\n",
        "            prob.append(ast.literal_eval(temp[1][:-1])[neuron - 1])\n",
        "\n",
        "        visualize_l(dec_seq, prob)\n",
        "        print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_conn(input_seq):\n",
        "            # Encode the input as state vectors.\n",
        "            if cell_type=='LSTM':\n",
        "              encoder_first_outputs,state_h,state_c= encoder_model.predict(input_seq)\n",
        "              states_value=[state_h,state_c]\n",
        "            else:\n",
        "              encoder_first_outputs,states_value= encoder_model.predict(input_seq)\n",
        "\n",
        "            # Generate empty target sequence of length 1.\n",
        "            empty_seq = np.zeros((1, 1))\n",
        "            empty_seq[0, 0] = target_token_index[\"\\t\"]\n",
        "            target_seq = empty_seq\n",
        "\n",
        "            # Sampling loop for a batch of sequences\n",
        "            # (to simplify, here we assume a batch of size 1).\n",
        "            stop_condition = False\n",
        "            decoded_sentence = \"\"\n",
        "            attention_weights = []\n",
        "            visualization_data = []\n",
        "            heatmap_data = []\n",
        "            while not stop_condition:\n",
        "                if cell_type == \"LSTM\":\n",
        "                    output_tokens, h, c,attn = decoder_model.predict([target_seq, encoder_first_outputs] + states_value)\n",
        "                elif cell_type == \"RNN\" or cell_type == \"GRU\":\n",
        "                    states_value = states_value[0].reshape((1, latent_dimension))\n",
        "                    output_tokens, h ,attn= decoder_model.predict([target_seq] + [encoder_first_outputs] + [states_value])\n",
        "                dec_ind = np.argmax(output_tokens, axis=-1)[0, 0]\n",
        "                #attention_weights.append((dec_ind, attn))\n",
        "                # Sample a token\n",
        "                sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "                sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "                decoded_sentence += sampled_char\n",
        "\n",
        "                # Exit condition: either hit max length\n",
        "                # or find stop character.\n",
        "                if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "                    stop_condition = True\n",
        "\n",
        "                # Update the target sequence (of length 1).\n",
        "                target_seq = np.zeros((1, 1))\n",
        "                target_seq[0, 0]= sampled_token_index\n",
        "                visualization_data.append((sampled_char, states_value[0]))\n",
        "                heatmap_data.append((sampled_char, attn))\n",
        "                # Update states\n",
        "                if cell_type == \"LSTM\":\n",
        "                    states_value = [h, c]\n",
        "                elif cell_type == \"RNN\" or cell_type == \"GRU\":\n",
        "                    states_value = [h]\n",
        "            return decoded_sentence,heatmap_data ,visualization_data"
      ],
      "metadata": {
        "id": "XhwlsDNSLj2s"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return [1/(1 + np.exp(-z)) for z in x]"
      ],
      "metadata": {
        "id": "04j6itrXKYQL"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import sample\n",
        "for_test=True\n",
        "subset=10\n",
        "count, visual_count, test_size = 0, 0, len(test_input_texts[0:subset])\n",
        "predictions_attention = open(\"predictions_attention.csv\", \"w\", encoding='utf-8')\n",
        "predictions_attention.write(\"Input Sentence,Predicted Sentence,Original Sentence\\n\")  \n",
        "\n",
        "visualisation_inputs = sample(range(test_size), 10)\n",
        "#visualisation_inputs = range(0,2)\n",
        "heatmaps = []\n",
        "\n",
        "\n",
        "for seq_index in range(test_size):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = test_encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_word, heatmap_data, visualization_data = decode_conn(input_seq)\n",
        "    orig_word = test_target_texts[seq_index][1:]\n",
        "\n",
        "    # print(\"-\")\n",
        "    # print(\"Input sentence:\", test_input_words[seq_index])\n",
        "    # print(\"Decoded sentence:\", decoded_word[:-1])\n",
        "    # print(\"Original sentence:\", orig_word[:-1])\n",
        "\n",
        "    predictions_attention.write(test_input_texts[seq_index] + \",\" + decoded_word[:-1] + \",\" + orig_word[:-1] + \"\\n\")\n",
        "\n",
        "    if(orig_word == decoded_word): count += 1\n",
        "    print(orig_word)\n",
        "    print(decoded_word)\n",
        "    \n",
        "    if for_test:\n",
        "      if seq_index in visualisation_inputs:\n",
        "          \n",
        "          # # Heatmap Pl\n",
        "          # heatmap = attention_heatmap(test_input_texts[seq_index], heatmap_data)\n",
        "          # #plt.show(heatmap)\n",
        "          # heatmaps.append(heatmap)\n",
        "          \n",
        "          print(\"create conn.txt\")\n",
        "          # Connectivity Visualization\n",
        "          with open(\"conn_vis.txt\", \"a\", encoding='utf-8') as filepointer:\n",
        "\n",
        "              '''' The logic to compute the  heatmap and true word '''\n",
        "\n",
        "              true_word = test_input_texts[seq_index]\n",
        "\n",
        "              ''' Writing data into the conv_vis.txt file for visualisation purpose '''\n",
        "              \n",
        "              filepointer.write(true_word)\n",
        "              filepointer.write(\"\\t\")\n",
        "              filepointer.write(str(len(heatmap_data)))\n",
        "              filepointer.write(\"\\n\")\n",
        "\n",
        "              for tup in range(len(heatmap_data)):\n",
        "                  dec_char = heatmap_data[tup][0]\n",
        "                  dec_char_prob = heatmap_data[tup][1].reshape(-1)\n",
        "                  #print(dec_char)\n",
        "                  #print(dec_char_prob)\n",
        "                  if tup == len(heatmap_data) - 1:\n",
        "                      filepointer.write(\"<e>\")\n",
        "                  else:\n",
        "                      filepointer.write(dec_char)\n",
        "                \n",
        "                  filepointer.write(\"\\t\")\n",
        "\n",
        "                  for p in range(len(true_word)):\n",
        "                      filepointer.write(str(dec_char_prob[p]))\n",
        "                      filepointer.write(\"\\t\")\n",
        "\n",
        "                  filepointer.write(\"\\n\")\n",
        "\n",
        "              filepointer.write(\"Next\\n\")\n",
        "\n",
        "          #print(\"nee\")\n",
        "          # LSTM Visualization\n",
        "          file = open(\"lstm_vis_\" + str(visual_count) + \".txt\", \"w\", encoding='utf-8')\n",
        "          file.write(test_input_texts[seq_index] + \"\\n\")\n",
        "\n",
        "          for i, data in enumerate(visualization_data):\n",
        "      \n",
        "              dec_char, neuron_activation  = data[0], sigmoid(data[1].reshape(-1))\n",
        "              \n",
        "              if i == len(visualization_data) - 1:\n",
        "                  file.write(\"<e>\" + \"\\t\" + str(neuron_activation) + \"\\n\")\n",
        "              else:\n",
        "                  file.write(dec_char + \"\\t\" + str(neuron_activation) + \"\\n\")\n",
        "\n",
        "          visual_count += 1"
      ],
      "metadata": {
        "id": "YVnmevmMIBbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e1e83a-3219-4e40-d66d-c55eb90eb4fb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ஃபார்ம்\n",
            "\n",
            "பார்ம்\n",
            "\n",
            "create conn.txt\n",
            "ஃபார்ம்\n",
            "\n",
            "பரம்\n",
            "\n",
            "create conn.txt\n",
            "ஃபார்ம்\n",
            "\n",
            "போர்ம்\n",
            "\n",
            "create conn.txt\n",
            "ஃபார்ம்\n",
            "\n",
            "பார்ம்\n",
            "\n",
            "create conn.txt\n",
            "ஃபேஸ்\n",
            "\n",
            "பேக்ஸ்\n",
            "\n",
            "create conn.txt\n",
            "ஃபேஸ்\n",
            "\n",
            "ஃபேஸ்\n",
            "\n",
            "create conn.txt\n",
            "ஃபேஸ்\n",
            "\n",
            "பேஸ்\n",
            "\n",
            "create conn.txt\n",
            "ஃபேஸ்\n",
            "\n",
            "பாஸ்\n",
            "\n",
            "create conn.txt\n",
            "ஃபேஸ்\n",
            "\n",
            "பாஷ்\n",
            "\n",
            "create conn.txt\n",
            "அஇஅதிமுக\n",
            "\n",
            "ஏதிமுக\n",
            "\n",
            "create conn.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_connectivity(10)\n",
        "visualize_lstm(10, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MiHRd6m4K1Mu",
        "outputId": "cbc1bcf4-8962-4de5-87f6-f1e14a7ea7f9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ா</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ர</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>m </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>m </text> <b> &emsp; ம</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; ர</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>m </text> <b> &emsp; ம</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>o </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>o </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; ோ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>o </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; ர</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>o </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>m </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>o </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>m </text> <b> &emsp; ம</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>o </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>o </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ா</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ர</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>m </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>m </text> <b> &emsp; ம</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>r </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>m </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>e </text> <b> &emsp; ே</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; க</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; ஸ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>f </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>s </text> <b> &emsp; ஃ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>s </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>s </text> <b> &emsp; ே</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>s </text> <b> &emsp; ஸ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>s </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>s </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>e </text> <b> &emsp; ே</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; ஸ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>c </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b5dfef>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>s </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>s </text> <b> &emsp; ா</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>s </text> <b> &emsp; ஸ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>s </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>s </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>s </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text> <b> &emsp; ப</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>s </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; ா</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c7e7f3>s </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>e </text> <b> &emsp; ஷ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>s </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; ்</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>p </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>s </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>t </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>i </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>m </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>u </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>k </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text> <b> &emsp; ஏ</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>t </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>i </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>m </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>u </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>k </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text> <b> &emsp; த</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>t </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>i </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>m </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>u </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>k </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text> <b> &emsp; ி</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>t </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>i </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>m </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>u </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>k </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text> <b> &emsp; ம</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>t </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>i </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>m </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>u </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>k </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text> <b> &emsp; ு</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>t </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>i </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>m </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>u </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#daeff7>k </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text> <b> &emsp; க</b>  &emsp; &emsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>e </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>a </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>t </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>h </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>i </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ffffff>m </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>u </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>k </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#ecf7fb>a </text> <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9bdbd>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9bdbd>ா </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>ர </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b2d9ec>ம </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b2d9ec>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#eff7fb><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9d4d4>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9d4d4>ர </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>ம </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9d4d4>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9d4d4>ோ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>ர </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>ம </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b2d9ec>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f8a8a8>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f8a8a8>ா </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c2e1f0>ர </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c2e1f0>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b2d9ec>ம </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b2d9ec>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#eff7fb><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9d4d4>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ே </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>க </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c2e1f0>ஸ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#b2d9ec>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ஃ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ே </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>ஸ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c2e1f0>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9d4d4>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ே </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>ஸ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ா </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c2e1f0>ஸ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#eff7fb>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9bdbd><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9d4d4>ப </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ா </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>ஷ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#baddee>் </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c2e1f0><e> </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f8a8a8>ஏ </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f8a8a8>த </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#c2e1f0>ி </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>ம </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#eff7fb>ு </text><text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:#f9e8e8>க </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model,cell_type,latent_dimension,test_input_texts ,verbose=True):\n",
        "        n_correct = 0\n",
        "        n_total = 0\n",
        "        index=1\n",
        "        queries = []\n",
        "        outputs = []\n",
        "        ground_truth=[]\n",
        "        attentions = []\n",
        "        fig = plt.figure(figsize=(10,10))\n",
        "        for seq_index in range(len(val_encoder_input_data)):\n",
        "            # Take one sequence (part of the training set)\n",
        "            # for trying out decoding.\n",
        "            input_seq = val_encoder_input_data[seq_index: seq_index + 1]\n",
        "            # Generate empty target sequence of length 1.\n",
        "            # empty_seq = np.zeros((1, 1))\n",
        "            # # Populate the first character of target sequence with the start character.\n",
        "            # empty_seq[0, 0] =  target_token_index[\"\\t\"]\n",
        "            decoded_sentence,att = decode_sequence(input_seq,n_decoder_layers,cell_type,encoder_model,decoder_model,latent_dimension)\n",
        "            #print(att)\n",
        "            # print(\"Done 1\")\n",
        "            if decoded_sentence.strip() == val_target_texts[seq_index].strip():\n",
        "                n_correct += 1\n",
        "\n",
        "            n_total += 1\n",
        "            #print(n_correct)\n",
        "\n",
        "            if verbose:\n",
        "                print('Prediction ', decoded_sentence.strip(), ',Ground Truth ', val_target_texts[seq_index].strip())\n",
        "            \n",
        "            #print(att)\n",
        "            attention=np.array(att)\n",
        "            print(input_seq)\n",
        "            print(attention.reshape(attention.shape[0],attention.shape[-1])[:len(decoded_sentence),:])\n",
        "            print(\"1\")\n",
        "            print(attention.shape)\n",
        "            print(attention.shape[-1])\n",
        "            # plt.subplot(3,3,index)\n",
        "            # plt.imshow(attention.reshape(attention.shape[0],attention.shape[-1])[:,:len(decoded_sentence)],cmap=\"Blues\")\n",
        "\n",
        "            # plt.xticks(range(attention.shape[0]),decoded_sentence,fontproperties=FontProperties(fname = 'Nirmala.ttf'))\n",
        "            # plt.yticks(range(attention.shape[0]),test_input_texts[seq_index])\n",
        "\n",
        "            queries.append(test_input_texts[seq_index])\n",
        "            outputs.append(decoded_sentence.strip())\n",
        "            #attentions.append(attention.reshape(attention.shape[0],attention.shape[-1])[:,:len(decoded_sentence)])\n",
        "            ground_truth.append(val_target_texts[seq_index].strip()) # To remove the tab and newline characters\n",
        "            index+=1\n",
        "        #plt.show()\n",
        "        df_train = pd.DataFrame({\"Input\": queries, \"Ground Truth\" : ground_truth, \"Model output\":outputs})\n",
        "        #print(df_train)\n",
        "        df_train.to_csv('predictions_attention.csv', index=False)\n",
        "        return n_correct * 100.0 / n_total"
      ],
      "metadata": {
        "id": "ZlClTo3fqaOu"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset = 1\n",
        "test_accuracy = accuracy(test_encoder_input_data[0:subset], test_target_texts[0:subset],n_decoder_layers,encoder_model,decoder_model,cell_type,latent_dimension,test_input_texts[0:subset]) if subset>0 \\\n",
        "    else accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model,cell_type,latent_dimension,test_input_texts)\n",
        "print('Test accuracy: ', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "GBGe4LH20Fsn",
        "outputId": "6baa3e39-8ff7-4bf7-b4a0-337fca0d8aaf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction  பார்ம் ,Ground Truth  ஃபார்ம்\n",
            "[[ 6.  1.  1. 18. 13.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.  0.]]\n",
            "[[9.0325630e-01 5.7176527e-02 2.5399841e-04 2.1971018e-06 2.6246675e-05\n",
            "  5.6690384e-05 1.1574106e-04]\n",
            " [1.2872710e-02 3.2256857e-02 8.9368850e-01 3.1814598e-02 1.7810657e-03\n",
            "  6.1841944e-04 4.0256290e-04]\n",
            " [6.0860103e-04 1.0331625e-03 1.6106665e-02 9.2713672e-01 3.8119260e-02\n",
            "  6.8390847e-04 1.4776373e-04]\n",
            " [1.1275454e-03 2.2427925e-04 1.7667808e-04 9.9554927e-05 9.2943138e-01\n",
            "  3.3093456e-02 4.9891551e-03]\n",
            " [4.9820734e-05 6.9900113e-04 2.9182725e-04 8.0647929e-05 9.7933620e-01\n",
            "  9.9417614e-03 6.6888786e-04]\n",
            " [1.7962824e-05 1.6821577e-04 3.6890045e-04 5.6519516e-06 7.4114540e-04\n",
            "  1.5436269e-01 4.2091426e-01]\n",
            " [1.2164499e-05 1.3966828e-04 3.3453955e-05 8.1282758e-07 1.6524042e-04\n",
            "  2.2285013e-03 3.2109812e-02]]\n",
            "1\n",
            "(7, 1, 1, 23)\n",
            "23\n",
            "Test accuracy:  0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "embedding_size=128\n",
        "n_encoder_tokens=num_encoder_tokens\n",
        "n_decoder_tokens=num_decoder_tokens\n",
        "n_encoder_layers=1\n",
        "n_decoder_layers=1\n",
        "latent_dimension=256\n",
        "cell_type='LSTM'\n",
        "target_token_index=target_token_index\n",
        "max_decoder_seq_length=max_decoder_seq_length\n",
        "reverse_target_char_index=reverse_target_char_index\n",
        "dropout=0.2"
      ],
      "metadata": {
        "id": "c1Tv3B8JEeH-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute test accuracy\n",
        "from matplotlib.font_manager import FontProperties\n",
        "print('Reading test data')\n",
        "test_data = \"dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\"\n",
        "# open and save the files to lists\n",
        "with open(test_data, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_lines = f.read().split(\"\\n\")\n",
        "# popping the last element of all the lists since it is empty character\n",
        "test_lines.pop()\n",
        "# embedding test\n",
        "# for test data, almost same\n",
        "test_input_texts = []\n",
        "test_target_texts = []\n",
        "for line in test_lines[: (len(test_lines) - 1)]:\n",
        "    target_text, input_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    test_input_texts.append(input_text)\n",
        "    test_target_texts.append(target_text)\n",
        "test_max_encoder_seq_length = max([len(txt) for txt in test_input_texts])\n",
        "test_max_decoder_seq_length = max([len(txt) for txt in test_target_texts])\n",
        "test_encoder_input_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "test_decoder_input_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "test_decoder_target_data = np.zeros(\n",
        "    (len(test_input_texts), test_max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "for i, (input_text, target_text) in enumerate(zip(test_input_texts, test_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        test_encoder_input_data[i, t] = input_token_index[char]\n",
        "    test_encoder_input_data[i, t + 1:] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        test_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            test_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    test_decoder_input_data[i, t + 1:] = target_token_index[\" \"]\n",
        "    test_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu11tIQ-pl4n",
        "outputId": "c7d30275-66c9-4eeb-9c97-6443fe0060d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading test data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calling rnn\n",
        "# encoder_model, decoder_model=seq2seq(embedding_size, n_encoder_tokens,n_decoder_tokens,n_encoder_layers, n_decoder_layers,latent_dimension,\n",
        "#                 cell_type, target_token_index, max_decoder_seq_length,reverse_target_char_index, dropout ,encoder_input_data, decoder_input_data,\n",
        "#                 decoder_target_data,batch_size,10)\n",
        "\n",
        "\n",
        "# val_accuracy= accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model)\n",
        "# print('Validation accuracy: ', val_accuracy)\n",
        "\n",
        "subset = 0\n",
        "test_accuracy = accuracy(test_encoder_input_data[0:subset], test_target_texts[0:subset],n_decoder_layers,encoder_model,decoder_model,cell_type,latent_dimension,test_input_texts[0:subset]) if subset>0 \\\n",
        "    else accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model,cell_type,latent_dimension,test_input_texts)\n",
        "print('Test accuracy: ', test_accuracy)"
      ],
      "metadata": {
        "id": "hAD6146NElT-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "444e3535-92a9-4597-92e7-e38c10ce9bc4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  55.99179607383534\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['Source', 'Predictions', 'GroundTruth'])\n",
        "n_correct = 0\n",
        "n_total = 0\n",
        "for seq_index in range(len(test_encoder_input_data)):\n",
        "    decoded_sentence = beam_search(test_encoder_input_data[seq_index:seq_index+1],encoder_model,decoder_model,beamSize,n_decoder_layers,cell_type)\n",
        "\n",
        "    if test_target_texts[seq_index].strip() == decoded_sentence[0][0].strip():\n",
        "        n_correct += 1\n",
        "\n",
        "    n_total += 1\n",
        "    row = {}\n",
        "    row['SourceText'] = test_input_texts[seq_index].strip()\n",
        "    row['GroundTruth'] = test_target_texts[seq_index].strip()\n",
        "    row['Prediction'] = decoded_sentence[0][0].strip()\n",
        "    df = df.append(row, ignore_index=True)\n",
        "df.to_csv('predictions_'+str(beamSize)+'.csv', index=False)  \n",
        "test_accuracy[beamSize] = (n_correct * 100.0 / n_total)\n",
        "print('Test accuracy ', test_accuracy)"
      ],
      "metadata": {
        "id": "fI4v1__yD7PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "EBYzP1lHfrIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  config_defaults = {\n",
        "            \"epochs\":15,\n",
        "            \"embedding_size\":256,\n",
        "            \"latent_dimension\":256,\n",
        "            \"cell_type\":'LSTM',\n",
        "            \"dropout\":0.2  \n",
        "        }\n",
        "  wandb.init(config=config_defaults)\n",
        "  \n",
        "  config = wandb.config\n",
        "  cell_type=config.cell_type\n",
        "  embedding_size=config.embedding_size\n",
        "  latent_dimension=config.latent_dimension\n",
        "  dropout=config.dropout\n",
        "  epochs=config.epochs\n",
        "  run_name = \"cell_type_{}_drop_{}_emd_{}_ld_{}\".format(cell_type, dropout, embedding_size, latent_dimension )\n",
        "  \n",
        "  encoder_model, decoder_model=seq2seq(embedding_size, n_encoder_tokens,n_decoder_tokens,n_encoder_layers, n_decoder_layers,latent_dimension,\n",
        "                cell_type, target_token_index, max_decoder_seq_length,reverse_target_char_index, dropout ,encoder_input_data, decoder_input_data,\n",
        "                decoder_target_data,batch_size,epochs)\n",
        "  \n",
        "  val_accuracy=accuracy(val_encoder_input_data, val_target_texts,n_decoder_layers,encoder_model,decoder_model,cell_type,latent_dimension)\n",
        "  print(\"Validation Accuracy:\", val_accuracy)\n",
        "  wandb.log({'val_accuracy': val_accuracy})\n",
        "  wandb.run.name = run_name\n",
        "  wandb.run.save()\n",
        "  wandb.run.finish()"
      ],
      "metadata": {
        "id": "H6EOW5yrbheb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'val_acc',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'early_terminate':{\n",
        "  'type': 'hyperband',\n",
        "  'min_iter': 5\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs':{\n",
        "          'values':[10,15]  \n",
        "        },\n",
        "        #embedding\n",
        "        'embedding_size': {\n",
        "            'values': [128,64,256]\n",
        "        },\n",
        "        'latent_dimension': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "        #100% means no fine tuning, only pre training\n",
        "        'cell_type':{\n",
        "            'values': ['RNN','GRU','LSTM']\n",
        "        \n",
        "        },\n",
        "        'dropout': {\n",
        "            'values':[0,0.2,0.3]\n",
        "        },\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "# sweep_id=wandb.sweep(sweep_config,entity=\"anandh\", project = \"CS6910_Assignment3_Attention\")\n",
        "# wandb.agent(sweep_id, train,count=5)\n",
        "sweep_id=\"yomq8g4r\"\n",
        "wandb.agent(sweep_id, train, entity=\"anandh\", project = \"CS6910_Assignment3_Attention\", count = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "N0t-BUcvRJ7A",
        "outputId": "76c8b24f-cd86-40a3-e001-d067214dec0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5gm0euz0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dimension: 256\n"
          ]
        }
      ]
    }
  ]
}